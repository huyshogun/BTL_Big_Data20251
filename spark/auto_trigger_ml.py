import json
import time
import subprocess
import os
import sys
from kafka import KafkaConsumer

# ==========================================
# Cáº¤U HÃŒNH
# ==========================================
KAFKA_TOPIC = "example_topic"
BOOTSTRAP_SERVERS = ['localhost:9097', 'localhost:9098', 'localhost:9099']
BATCH_SIZE = 10  # Sá»‘ lÆ°á»£ng báº£n ghi Ä‘á»ƒ kÃ­ch hoáº¡t training (Báº¡n cÃ³ thá»ƒ Ä‘á»•i thÃ nh 100, 1000)
SPARK_ML_FILE = "sparkML.py" # TÃªn file ML cáº§n cháº¡y

# Äáº£m báº£o Ä‘Æ°á»ng dáº«n Python Ä‘Ãºng (trÃ¡nh lá»—i khÃ´ng tÃ¬m tháº¥y thÆ° viá»‡n)
PYTHON_EXECUTABLE = sys.executable 

def run_spark_ml_job():
    print(f"\n{'='*50}")
    print(f"âš¡ ÄÃ£ Ä‘á»§ {BATCH_SIZE} báº£n ghi má»›i. KÃ­ch hoáº¡t Spark ML...")
    print(f"{'='*50}")
    
    # Chá» 5 giÃ¢y Ä‘á»ƒ Ä‘áº£m báº£o dá»¯ liá»‡u tá»« Kafka ká»‹p trÃ´i vÃ o Cassandra
    # (VÃ¬ Spark Streaming cáº§n vÃ i giÃ¢y Ä‘á»ƒ xá»­ lÃ½ vÃ  ghi xuá»‘ng DB)
    print("â³ Äang Ä‘á»£i 5s Ä‘á»ƒ dá»¯ liá»‡u Ä‘á»“ng bá»™ xuá»‘ng Cassandra...")
    time.sleep(5)
    
    try:
        # Gá»i lá»‡nh cháº¡y file sparkML.py
        # Sá»­ dá»¥ng check=True Ä‘á»ƒ bÃ¡o lá»—i náº¿u file ML cháº¡y tháº¥t báº¡i
        subprocess.run([PYTHON_EXECUTABLE, SPARK_ML_FILE], check=True)
        print(f"\nâœ… Training hoÃ n táº¥t! Dashboard Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t.")
    except subprocess.CalledProcessError as e:
        print(f"âŒ Lá»—i khi cháº¡y Spark ML: {e}")
    except Exception as e:
        print(f"âŒ Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {e}")

    print(f"\nðŸ‘€ Äang tiáº¿p tá»¥c láº¯ng nghe Kafka...")

def start_watcher():
    print(f">>> Äang khá»Ÿi Ä‘á»™ng trÃ¬nh giÃ¡m sÃ¡t (Watcher)...")
    print(f">>> Má»¥c tiÃªu: Cá»© má»—i {BATCH_SIZE} tin nháº¯n sáº½ cháº¡y láº¡i {SPARK_ML_FILE}")

    consumer = KafkaConsumer(
        KAFKA_TOPIC,
        bootstrap_servers=BOOTSTRAP_SERVERS,
        auto_offset_reset='latest', # Chá»‰ tÃ­nh tin nháº¯n má»›i tá»« lÃºc báº­t script nÃ y
        enable_auto_commit=True,
        value_deserializer=lambda x: json.loads(x.decode('utf-8'))
    )

    message_count = 0

    print(">>> Sáºµn sÃ ng! Äang chá» Producer báº¯n tin...")
    
    for message in consumer:
        # In ra tin nháº¯n nhá» gá»n Ä‘á»ƒ biáº¿t cÃ³ dá»¯ liá»‡u vÃ o
        data = message.value
        print(f"[Watcher] Nháº­n tin: {data.get('address', 'Unknown')} | Count: {message_count + 1}/{BATCH_SIZE}")
        
        message_count += 1

        # Kiá»ƒm tra Ä‘iá»u kiá»‡n Trigger
        if message_count >= BATCH_SIZE:
            run_spark_ml_job()
            message_count = 0 # Reset bá»™ Ä‘áº¿m

if __name__ == "__main__":
    start_watcher()