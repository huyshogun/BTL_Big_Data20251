2026-01-12 19:25:31,267 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9098 <connecting> [IPv6 ('::1', 9098, 0, 0)]>: connecting to localhost:9098 [('::1', 9098, 0, 0) IPv6]
2026-01-12 19:25:31,493 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9098 <checking_api_versions_recv> [IPv6 ('::1', 9098, 0, 0)]>: Broker version identified as 2.6
2026-01-12 19:25:31,494 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Connection complete.
2026-01-12 19:25:31,496 - kafka.consumer.subscription_state - INFO - Updating subscribed topics to: ('example_topic',)
2026-01-12 19:25:31,497 - hdfs.client - INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
2026-01-12 19:25:31,571 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=3 host=localhost:9099 <connecting> [IPv6 ('::1', 9099, 0, 0)]>: connecting to localhost:9099 [('::1', 9099, 0, 0) IPv6]
2026-01-12 19:25:31,573 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=3 host=localhost:9099 <connected> [IPv6 ('::1', 9099, 0, 0)]>: Connection complete.
2026-01-12 19:25:31,575 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Closing connection. 
2026-01-12 19:25:31,758 - kafka.cluster - INFO - Coordinator for group/hdfs_archiver_group is BrokerMetadata(nodeId='coordinator-1', host='localhost', port=9097, rack=None)
2026-01-12 19:25:31,758 - kafka.coordinator - INFO - Discovered coordinator coordinator-1 for group hdfs_archiver_group
2026-01-12 19:25:31,761 - kafka.coordinator.heartbeat - INFO - Starting new heartbeat thread
2026-01-12 19:25:31,763 - kafka.coordinator.consumer - INFO - Revoking previously assigned partitions set() for group hdfs_archiver_group
2026-01-12 19:25:31,764 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: NodeNotReadyError: coordinator-1
2026-01-12 19:25:31,766 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-12 19:25:31,768 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-12 19:25:31,885 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-12 19:25:33,161 - kafka.coordinator - INFO - Received member id kafka-python-2.3.0-245fd4eb-b07e-4a9c-8a9a-2d690f350eff for group hdfs_archiver_group; will retry join-group
2026-01-12 19:25:33,162 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: [Error 79] MemberIdRequiredError
2026-01-12 19:25:33,164 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-12 19:25:36,710 - kafka.coordinator - INFO - Successfully joined group hdfs_archiver_group <Generation 1 (member_id: kafka-python-2.3.0-245fd4eb-b07e-4a9c-8a9a-2d690f350eff, protocol: range)>
2026-01-12 19:25:36,710 - kafka.coordinator - INFO - Elected group leader -- performing partition assignments using range
2026-01-12 19:25:37,375 - kafka.consumer.subscription_state - INFO - Updated partition assignment: [TopicPartition(topic='example_topic', partition=0)]
2026-01-12 19:25:37,378 - kafka.coordinator.consumer - INFO - Setting newly assigned partitions {TopicPartition(topic='example_topic', partition=0)} for group hdfs_archiver_group
2026-01-12 19:25:37,449 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connecting> [IPv6 ('::1', 9098, 0, 0)]>: connecting to localhost:9098 [('::1', 9098, 0, 0) IPv6]
2026-01-12 19:25:37,450 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Connection complete.
2026-01-12 19:25:37,505 - kafka.consumer.fetcher - INFO - Resetting offset for partition TopicPartition(topic='example_topic', partition=0) to offset 0.
2026-01-12 19:25:38,285 - __main__ - INFO - Trigger write: 500 msgs (Timeout: False, Full: True)
2026-01-12 19:25:38,291 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 19:25:38,551 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_19_25_38_500.json'.
2026-01-12 19:25:48,166 - __main__ - INFO - Trigger write: 290 msgs (Timeout: False, Full: True)
2026-01-12 19:25:48,175 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 19:25:48,215 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_19_25_48_290.json'.
2026-01-12 19:25:56,301 - __main__ - INFO - Trigger write: 500 msgs (Timeout: False, Full: True)
2026-01-12 19:25:56,307 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 19:25:56,321 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_19_25_56_500.json'.
2026-01-12 19:26:06,960 - __main__ - INFO - Trigger write: 289 msgs (Timeout: False, Full: True)
2026-01-12 19:26:06,968 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 19:26:06,996 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_19_26_06_289.json'.
2026-01-12 19:26:17,441 - __main__ - INFO - Trigger write: 500 msgs (Timeout: False, Full: True)
2026-01-12 19:26:17,461 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 19:26:17,502 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_19_26_17_500.json'.
2026-01-12 19:26:35,925 - __main__ - INFO - Trigger write: 289 msgs (Timeout: False, Full: True)
2026-01-12 19:26:35,939 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 19:26:36,022 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_19_26_35_289.json'.
2026-01-12 19:26:46,384 - __main__ - INFO - Trigger write: 500 msgs (Timeout: False, Full: True)
2026-01-12 19:26:46,399 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 19:26:46,426 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_19_26_46_500.json'.
2026-01-12 19:26:59,068 - __main__ - INFO - Trigger write: 289 msgs (Timeout: False, Full: True)
2026-01-12 19:26:59,082 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 19:26:59,124 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_19_26_59_289.json'.
2026-01-12 19:27:06,226 - __main__ - INFO - Trigger write: 500 msgs (Timeout: False, Full: True)
2026-01-12 19:27:06,257 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 19:27:06,290 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_19_27_06_500.json'.
2026-01-12 19:27:20,432 - __main__ - INFO - Trigger write: 289 msgs (Timeout: False, Full: True)
2026-01-12 19:27:20,464 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 19:27:20,537 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_19_27_20_289.json'.
2026-01-12 19:27:28,944 - __main__ - INFO - Trigger write: 500 msgs (Timeout: False, Full: True)
2026-01-12 19:27:28,962 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 19:27:28,993 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_19_27_28_500.json'.
2026-01-12 19:27:41,527 - __main__ - INFO - Trigger write: 290 msgs (Timeout: False, Full: True)
2026-01-12 19:27:41,547 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 19:27:41,634 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_19_27_41_290.json'.
2026-01-12 19:27:51,284 - __main__ - INFO - Trigger write: 439 msgs (Timeout: False, Full: True)
2026-01-12 19:27:51,288 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 19:27:51,299 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_19_27_51_439.json'.
2026-01-12 19:27:58,530 - __main__ - INFO - Consumer stopped by user.
2026-01-12 19:28:00,539 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 19:28:00,554 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_19_28_00_439.json'.
2026-01-12 19:29:17,029 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-1 host=localhost:9098 <connecting> [IPv6 ('::1', 9098, 0, 0)]>: connecting to localhost:9098 [('::1', 9098, 0, 0) IPv6]
2026-01-12 19:29:17,045 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-1 host=localhost:9098 <checking_api_versions_recv> [IPv6 ('::1', 9098, 0, 0)]>: Broker version identified as 2.6
2026-01-12 19:29:17,046 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-1 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Connection complete.
2026-01-12 19:29:17,050 - kafka.consumer.subscription_state - INFO - Updating subscribed topics to: ('example_topic',)
2026-01-12 19:29:17,050 - hdfs.client - INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
2026-01-12 19:29:17,056 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connecting> [IPv6 ('::1', 9098, 0, 0)]>: connecting to localhost:9098 [('::1', 9098, 0, 0) IPv6]
2026-01-12 19:29:17,059 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Connection complete.
2026-01-12 19:29:17,060 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-1 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Closing connection. 
2026-01-12 19:29:17,168 - kafka.cluster - INFO - Coordinator for group/hdfs_archiver_group is BrokerMetadata(nodeId='coordinator-1', host='localhost', port=9097, rack=None)
2026-01-12 19:29:17,168 - kafka.coordinator - INFO - Discovered coordinator coordinator-1 for group hdfs_archiver_group
2026-01-12 19:29:17,170 - kafka.coordinator.heartbeat - INFO - Starting new heartbeat thread
2026-01-12 19:29:17,172 - kafka.coordinator.consumer - INFO - Revoking previously assigned partitions set() for group hdfs_archiver_group
2026-01-12 19:29:17,172 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: NodeNotReadyError: coordinator-1
2026-01-12 19:29:17,174 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-12 19:29:17,175 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-12 19:29:17,289 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-12 19:29:17,298 - kafka.coordinator - INFO - Received member id kafka-python-2.3.0-c134733c-ed92-4f1e-b2e6-712d20d2e5b7 for group hdfs_archiver_group; will retry join-group
2026-01-12 19:29:17,299 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: [Error 79] MemberIdRequiredError
2026-01-12 19:29:17,300 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-12 19:29:20,554 - kafka.coordinator - INFO - Successfully joined group hdfs_archiver_group <Generation 3 (member_id: kafka-python-2.3.0-c134733c-ed92-4f1e-b2e6-712d20d2e5b7, protocol: range)>
2026-01-12 19:29:20,555 - kafka.coordinator - INFO - Elected group leader -- performing partition assignments using range
2026-01-12 19:29:20,570 - kafka.consumer.subscription_state - INFO - Updated partition assignment: [TopicPartition(topic='example_topic', partition=0)]
2026-01-12 19:29:20,571 - kafka.coordinator.consumer - INFO - Setting newly assigned partitions {TopicPartition(topic='example_topic', partition=0)} for group hdfs_archiver_group
2026-01-12 19:29:20,949 - __main__ - INFO - Trigger write: 439 msgs (Timeout: False, Full: True)
2026-01-12 19:29:20,951 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 19:29:20,984 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_19_29_20_439.json'.
2026-01-12 19:29:25,976 - __main__ - INFO - >>> Đã lưu 439 tin vào HDFS: /data/kafka_messages\2026\01\12\batdongsan_19_29_20_439.json
2026-01-12 19:34:20,564 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=3 host=localhost:9099 <connecting> [IPv6 ('::1', 9099, 0, 0)]>: connecting to localhost:9099 [('::1', 9099, 0, 0) IPv6]
2026-01-12 19:34:20,567 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=3 host=localhost:9099 <connected> [IPv6 ('::1', 9099, 0, 0)]>: Connection complete.
2026-01-12 19:53:42,566 - __main__ - INFO - Trigger write: 31 msgs (Timeout: True, Full: False)
2026-01-12 19:53:42,567 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 19:54:12,593 - __main__ - ERROR - Error creating HDFS directory /data/kafka_messages\2026\01\12: ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))
2026-01-12 19:54:12,595 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_19_53_42_31.json'.
2026-01-12 19:54:13,979 - __main__ - INFO - >>> Đã lưu 31 tin vào HDFS: /data/kafka_messages\2026\01\12\batdongsan_19_53_42_31.json
2026-01-12 19:59:18,543 - __main__ - INFO - Trigger write: 32 msgs (Timeout: True, Full: False)
2026-01-12 19:59:18,545 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 19:59:18,744 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_19_59_18_32.json'.
2026-01-12 19:59:20,196 - __main__ - INFO - >>> Đã lưu 32 tin vào HDFS: /data/kafka_messages\2026\01\12\batdongsan_19_59_18_32.json
2026-01-12 20:04:26,561 - __main__ - INFO - Trigger write: 37 msgs (Timeout: True, Full: False)
2026-01-12 20:04:26,566 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 20:04:26,616 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_20_04_26_37.json'.
2026-01-12 20:04:29,743 - __main__ - INFO - >>> Đã lưu 37 tin vào HDFS: /data/kafka_messages\2026\01\12\batdongsan_20_04_26_37.json
2026-01-12 20:09:31,780 - __main__ - INFO - Trigger write: 41 msgs (Timeout: True, Full: False)
2026-01-12 20:09:31,788 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 20:09:31,851 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_20_09_31_41.json'.
2026-01-12 20:09:35,251 - __main__ - INFO - >>> Đã lưu 41 tin vào HDFS: /data/kafka_messages\2026\01\12\batdongsan_20_09_31_41.json
2026-01-12 20:14:35,716 - __main__ - INFO - Trigger write: 39 msgs (Timeout: True, Full: False)
2026-01-12 20:14:35,721 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 20:14:35,773 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_20_14_35_39.json'.
2026-01-12 20:14:36,752 - __main__ - INFO - >>> Đã lưu 39 tin vào HDFS: /data/kafka_messages\2026\01\12\batdongsan_20_14_35_39.json
2026-01-12 20:19:39,257 - __main__ - INFO - Trigger write: 38 msgs (Timeout: True, Full: False)
2026-01-12 20:19:39,269 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 20:19:39,390 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_20_19_39_38.json'.
2026-01-12 20:19:41,601 - __main__ - INFO - >>> Đã lưu 38 tin vào HDFS: /data/kafka_messages\2026\01\12\batdongsan_20_19_39_38.json
2026-01-12 20:24:42,407 - __main__ - INFO - Trigger write: 41 msgs (Timeout: True, Full: False)
2026-01-12 20:24:42,416 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 20:24:42,508 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_20_24_42_41.json'.
2026-01-12 20:24:44,664 - __main__ - INFO - >>> Đã lưu 41 tin vào HDFS: /data/kafka_messages\2026\01\12\batdongsan_20_24_42_41.json
2026-01-12 20:29:46,386 - __main__ - INFO - Trigger write: 38 msgs (Timeout: True, Full: False)
2026-01-12 20:29:46,396 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 20:29:46,511 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_20_29_46_38.json'.
2026-01-12 20:29:49,221 - __main__ - INFO - >>> Đã lưu 38 tin vào HDFS: /data/kafka_messages\2026\01\12\batdongsan_20_29_46_38.json
2026-01-12 20:34:49,784 - __main__ - INFO - Trigger write: 41 msgs (Timeout: True, Full: False)
2026-01-12 20:34:49,807 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\12'.
2026-01-12 20:34:50,033 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\12\\batdongsan_20_34_49_41.json'.
2026-01-12 20:34:54,172 - __main__ - INFO - >>> Đã lưu 41 tin vào HDFS: /data/kafka_messages\2026\01\12\batdongsan_20_34_49_41.json
2026-01-20 15:20:57,971 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-20 15:20:57,986 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9097 <checking_api_versions_recv> [IPv6 ('::1', 9097, 0, 0)]>: Broker version identified as 2.6
2026-01-20 15:20:57,987 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-20 15:20:57,988 - kafka.consumer.subscription_state - INFO - Updating subscribed topics to: ('example_topic',)
2026-01-20 15:20:57,989 - hdfs.client - INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
2026-01-20 15:20:58,021 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-20 15:20:58,022 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-20 15:20:58,022 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-20 15:20:58,136 - kafka.cluster - INFO - Coordinator for group/hdfs_archiver_group is BrokerMetadata(nodeId='coordinator-1', host='localhost', port=9097, rack=None)
2026-01-20 15:20:58,136 - kafka.coordinator - INFO - Discovered coordinator coordinator-1 for group hdfs_archiver_group
2026-01-20 15:20:58,136 - kafka.coordinator.heartbeat - INFO - Starting new heartbeat thread
2026-01-20 15:20:58,139 - kafka.coordinator.consumer - INFO - Revoking previously assigned partitions set() for group hdfs_archiver_group
2026-01-20 15:20:58,139 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: NodeNotReadyError: coordinator-1
2026-01-20 15:20:58,141 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-20 15:20:58,142 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-20 15:20:58,255 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-20 15:20:58,273 - kafka.coordinator - INFO - Received member id kafka-python-2.3.0-449d3a39-7aa6-4170-aa97-6b842b700d0e for group hdfs_archiver_group; will retry join-group
2026-01-20 15:20:58,273 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: [Error 79] MemberIdRequiredError
2026-01-20 15:20:58,273 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-20 15:21:01,408 - kafka.coordinator - INFO - Successfully joined group hdfs_archiver_group <Generation 5 (member_id: kafka-python-2.3.0-449d3a39-7aa6-4170-aa97-6b842b700d0e, protocol: range)>
2026-01-20 15:21:01,408 - kafka.coordinator - INFO - Elected group leader -- performing partition assignments using range
2026-01-20 15:21:01,541 - kafka.consumer.subscription_state - INFO - Updated partition assignment: [TopicPartition(topic='example_topic', partition=0)]
2026-01-20 15:21:01,541 - kafka.coordinator.consumer - INFO - Setting newly assigned partitions {TopicPartition(topic='example_topic', partition=0)} for group hdfs_archiver_group
2026-01-20 15:21:01,554 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connecting> [IPv6 ('::1', 9098, 0, 0)]>: connecting to localhost:9098 [('::1', 9098, 0, 0) IPv6]
2026-01-20 15:21:01,555 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Connection complete.
2026-01-20 15:21:01,576 - kafka.consumer.fetcher - INFO - Fetch offset 5513 is out of range for topic-partition TopicPartition(topic='example_topic', partition=0)
2026-01-20 15:21:01,597 - kafka.consumer.fetcher - INFO - Resetting offset for partition TopicPartition(topic='example_topic', partition=0) to offset 5530.
2026-01-20 15:26:01,761 - __main__ - INFO - Trigger write: 54 msgs (Timeout: True, Full: False)
2026-01-20 15:26:01,776 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 15:26:23,443 - hdfs.client - INFO - Creating directories to '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 15:26:23,742 - __main__ - INFO - Created HDFS directory: /data/kafka_messages\2026\01\20
2026-01-20 15:26:23,759 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_15_26_01_54.json'.
2026-01-20 15:26:35,298 - __main__ - INFO - >>> Đã lưu 54 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_15_26_01_54.json
2026-01-20 15:31:36,295 - __main__ - INFO - Trigger write: 43 msgs (Timeout: True, Full: False)
2026-01-20 15:31:36,311 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 15:31:36,490 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_15_31_36_43.json'.
2026-01-20 15:31:38,399 - __main__ - INFO - >>> Đã lưu 43 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_15_31_36_43.json
2026-01-20 15:33:55,912 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-20 15:33:55,972 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9097 <checking_api_versions_recv> [IPv6 ('::1', 9097, 0, 0)]>: Broker version identified as 2.6
2026-01-20 15:33:55,979 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-20 15:33:55,981 - kafka.consumer.subscription_state - INFO - Updating subscribed topics to: ('example_topic',)
2026-01-20 15:33:55,986 - hdfs.client - INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
2026-01-20 15:33:56,011 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=3 host=localhost:9099 <connecting> [IPv6 ('::1', 9099, 0, 0)]>: connecting to localhost:9099 [('::1', 9099, 0, 0) IPv6]
2026-01-20 15:33:56,024 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=3 host=localhost:9099 <connected> [IPv6 ('::1', 9099, 0, 0)]>: Connection complete.
2026-01-20 15:33:56,041 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-20 15:33:56,185 - kafka.cluster - INFO - Coordinator for group/hdfs_archiver_group is BrokerMetadata(nodeId='coordinator-1', host='localhost', port=9097, rack=None)
2026-01-20 15:33:56,191 - kafka.coordinator - INFO - Discovered coordinator coordinator-1 for group hdfs_archiver_group
2026-01-20 15:33:56,197 - kafka.coordinator.heartbeat - INFO - Starting new heartbeat thread
2026-01-20 15:33:56,208 - kafka.coordinator.consumer - INFO - Revoking previously assigned partitions set() for group hdfs_archiver_group
2026-01-20 15:33:56,213 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: NodeNotReadyError: coordinator-1
2026-01-20 15:33:56,226 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-20 15:33:56,233 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-20 15:33:56,348 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-20 15:33:56,358 - kafka.coordinator - INFO - Received member id kafka-python-2.3.0-6ac06959-76c4-4354-8e73-587eb20e374b for group hdfs_archiver_group; will retry join-group
2026-01-20 15:33:56,374 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: [Error 79] MemberIdRequiredError
2026-01-20 15:33:56,390 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-20 15:33:59,577 - kafka.coordinator - INFO - Successfully joined group hdfs_archiver_group <Generation 7 (member_id: kafka-python-2.3.0-6ac06959-76c4-4354-8e73-587eb20e374b, protocol: range)>
2026-01-20 15:33:59,595 - kafka.coordinator - INFO - Elected group leader -- performing partition assignments using range
2026-01-20 15:33:59,659 - kafka.consumer.subscription_state - INFO - Updated partition assignment: [TopicPartition(topic='example_topic', partition=0)]
2026-01-20 15:33:59,681 - kafka.coordinator.consumer - INFO - Setting newly assigned partitions {TopicPartition(topic='example_topic', partition=0)} for group hdfs_archiver_group
2026-01-20 15:33:59,721 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connecting> [IPv6 ('::1', 9098, 0, 0)]>: connecting to localhost:9098 [('::1', 9098, 0, 0) IPv6]
2026-01-20 15:33:59,773 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Connection complete.
2026-01-20 15:38:59,886 - __main__ - INFO - Trigger write: 60 msgs (Timeout: True, Full: False)
2026-01-20 15:38:59,909 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 15:39:00,100 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_15_38_59_60.json'.
2026-01-20 15:39:02,710 - __main__ - INFO - >>> Đã lưu 60 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_15_38_59_60.json
2026-01-20 15:44:03,486 - __main__ - INFO - Trigger write: 39 msgs (Timeout: True, Full: False)
2026-01-20 15:44:03,490 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 15:44:03,552 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_15_44_03_39.json'.
2026-01-20 15:44:05,084 - __main__ - INFO - >>> Đã lưu 39 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_15_44_03_39.json
2026-01-20 15:49:10,733 - __main__ - INFO - Trigger write: 42 msgs (Timeout: True, Full: False)
2026-01-20 15:49:10,738 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 15:49:10,872 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_15_49_10_42.json'.
2026-01-20 15:49:13,842 - __main__ - INFO - >>> Đã lưu 42 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_15_49_10_42.json
2026-01-20 15:52:59,648 - kafka.client - INFO - Closing idle connection 3, last active 540005 ms ago
2026-01-20 15:52:59,654 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=3 host=localhost:9099 <connected> [IPv6 ('::1', 9099, 0, 0)]>: Closing connection. 
2026-01-20 15:53:59,683 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-20 15:53:59,688 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-20 15:54:17,306 - __main__ - INFO - Trigger write: 38 msgs (Timeout: True, Full: False)
2026-01-20 15:54:17,313 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 15:54:17,351 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_15_54_17_38.json'.
2026-01-20 15:54:19,323 - __main__ - INFO - >>> Đã lưu 38 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_15_54_17_38.json
2026-01-20 15:59:19,648 - __main__ - INFO - Trigger write: 42 msgs (Timeout: True, Full: False)
2026-01-20 15:59:19,660 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 15:59:19,720 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_15_59_19_42.json'.
2026-01-20 15:59:22,001 - __main__ - INFO - >>> Đã lưu 42 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_15_59_19_42.json
2026-01-20 16:04:25,391 - __main__ - INFO - Trigger write: 17 msgs (Timeout: True, Full: False)
2026-01-20 16:04:25,392 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 16:04:25,440 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_16_04_25_17.json'.
2026-01-20 16:04:26,267 - __main__ - INFO - >>> Đã lưu 17 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_16_04_25_17.json
2026-01-20 20:12:53,860 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-20 20:12:53,970 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9097 <checking_api_versions_recv> [IPv6 ('::1', 9097, 0, 0)]>: Broker version identified as 2.6
2026-01-20 20:12:53,975 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-20 20:12:53,981 - kafka.consumer.subscription_state - INFO - Updating subscribed topics to: ('example_topic',)
2026-01-20 20:12:53,984 - hdfs.client - INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
2026-01-20 20:12:54,084 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-20 20:12:54,085 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-20 20:12:54,086 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-20 20:12:54,211 - kafka.cluster - INFO - Coordinator for group/hdfs_archiver_group is BrokerMetadata(nodeId='coordinator-1', host='localhost', port=9097, rack=None)
2026-01-20 20:12:54,211 - kafka.coordinator - INFO - Discovered coordinator coordinator-1 for group hdfs_archiver_group
2026-01-20 20:12:54,213 - kafka.coordinator.heartbeat - INFO - Starting new heartbeat thread
2026-01-20 20:12:54,214 - kafka.coordinator.consumer - INFO - Revoking previously assigned partitions set() for group hdfs_archiver_group
2026-01-20 20:12:54,216 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: NodeNotReadyError: coordinator-1
2026-01-20 20:12:54,217 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-20 20:12:54,221 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-20 20:12:54,330 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-20 20:12:54,413 - kafka.coordinator - INFO - Received member id kafka-python-2.3.0-23e4b3dc-7023-4d94-8b8d-10b3606c494b for group hdfs_archiver_group; will retry join-group
2026-01-20 20:12:54,414 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: [Error 79] MemberIdRequiredError
2026-01-20 20:12:54,416 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-20 20:12:57,775 - kafka.coordinator - INFO - Successfully joined group hdfs_archiver_group <Generation 9 (member_id: kafka-python-2.3.0-23e4b3dc-7023-4d94-8b8d-10b3606c494b, protocol: range)>
2026-01-20 20:12:57,775 - kafka.coordinator - INFO - Elected group leader -- performing partition assignments using range
2026-01-20 20:12:58,027 - kafka.consumer.subscription_state - INFO - Updated partition assignment: [TopicPartition(topic='example_topic', partition=0)]
2026-01-20 20:12:58,028 - kafka.coordinator.consumer - INFO - Setting newly assigned partitions {TopicPartition(topic='example_topic', partition=0)} for group hdfs_archiver_group
2026-01-20 20:12:58,194 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connecting> [IPv6 ('::1', 9098, 0, 0)]>: connecting to localhost:9098 [('::1', 9098, 0, 0) IPv6]
2026-01-20 20:12:58,203 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Connection complete.
2026-01-20 20:17:58,897 - __main__ - INFO - Trigger write: 56 msgs (Timeout: True, Full: False)
2026-01-20 20:17:58,906 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 20:18:14,307 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_20_17_58_56.json'.
2026-01-20 20:18:24,798 - __main__ - INFO - >>> Đã lưu 56 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_20_17_58_56.json
2026-01-20 20:23:25,871 - __main__ - INFO - Trigger write: 43 msgs (Timeout: True, Full: False)
2026-01-20 20:23:25,884 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 20:23:25,968 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_20_23_25_43.json'.
2026-01-20 20:23:28,013 - __main__ - INFO - >>> Đã lưu 43 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_20_23_25_43.json
2026-01-20 20:28:28,943 - __main__ - INFO - Trigger write: 40 msgs (Timeout: True, Full: False)
2026-01-20 20:28:28,962 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 20:28:29,161 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_20_28_28_40.json'.
2026-01-20 20:28:30,775 - __main__ - INFO - >>> Đã lưu 40 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_20_28_28_40.json
2026-01-20 20:33:34,517 - __main__ - INFO - Trigger write: 40 msgs (Timeout: True, Full: False)
2026-01-20 20:33:34,534 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 20:33:34,711 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_20_33_34_40.json'.
2026-01-20 20:33:37,044 - __main__ - INFO - >>> Đã lưu 40 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_20_33_34_40.json
2026-01-20 20:38:38,074 - __main__ - INFO - Trigger write: 40 msgs (Timeout: True, Full: False)
2026-01-20 20:38:38,103 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 20:38:38,144 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_20_38_38_40.json'.
2026-01-20 20:38:38,216 - __main__ - ERROR - Lỗi ghi HDFS: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2026-01-20 20:43:42,954 - __main__ - INFO - Trigger write: 36 msgs (Timeout: True, Full: False)
2026-01-20 20:43:42,966 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 20:43:51,872 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_20_43_42_36.json'.
2026-01-20 20:43:51,927 - __main__ - ERROR - Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-20 20:46:12,466 - __main__ - INFO - Consumer stopped by user.
2026-01-20 20:46:12,474 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 20:46:12,549 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_20_46_12_20.json'.
2026-01-20 20:46:12,581 - __main__ - ERROR - Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-20 20:46:12,593 - kafka.coordinator.heartbeat - INFO - Stopping heartbeat thread
2026-01-20 20:46:12,595 - kafka.coordinator - INFO - Leaving consumer group hdfs_archiver_group (member kafka-python-2.3.0-23e4b3dc-7023-4d94-8b8d-10b3606c494b).
2026-01-20 20:46:12,769 - kafka.coordinator - INFO - LeaveGroup request for group hdfs_archiver_group returned successfully
2026-01-20 20:46:12,775 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-20 20:46:12,792 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-20 20:46:12,826 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Closing connection. 
2026-01-20 20:46:19,134 - __main__ - INFO - Khởi động Consumer... Batch Size: 10, Timeout: 60s
2026-01-20 20:46:19,179 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-2 host=localhost:9098 <connecting> [IPv6 ('::1', 9098, 0, 0)]>: connecting to localhost:9098 [('::1', 9098, 0, 0) IPv6]
2026-01-20 20:46:19,255 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-2 host=localhost:9098 <checking_api_versions_recv> [IPv6 ('::1', 9098, 0, 0)]>: Broker version identified as 2.6
2026-01-20 20:46:19,261 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Connection complete.
2026-01-20 20:46:19,271 - kafka.consumer.subscription_state - INFO - Updating subscribed topics to: ('example_topic',)
2026-01-20 20:46:19,278 - hdfs.client - INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
2026-01-20 20:46:19,279 - __main__ - INFO - Kết nối HDFS thành công tại: http://localhost:9870
2026-01-20 20:46:19,295 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-20 20:46:19,305 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-20 20:46:19,318 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Closing connection. 
2026-01-20 20:46:19,473 - kafka.cluster - INFO - Coordinator for group/hdfs_archiver_group is BrokerMetadata(nodeId='coordinator-1', host='localhost', port=9097, rack=None)
2026-01-20 20:46:19,483 - kafka.coordinator - INFO - Discovered coordinator coordinator-1 for group hdfs_archiver_group
2026-01-20 20:46:19,493 - kafka.coordinator.heartbeat - INFO - Starting new heartbeat thread
2026-01-20 20:46:19,524 - kafka.coordinator.consumer - INFO - Revoking previously assigned partitions set() for group hdfs_archiver_group
2026-01-20 20:46:19,539 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: NodeNotReadyError: coordinator-1
2026-01-20 20:46:19,541 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-20 20:46:19,550 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-20 20:46:19,666 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-20 20:46:19,720 - kafka.coordinator - INFO - Received member id kafka-python-2.3.0-1d9d9211-1e8d-4aa6-baf6-07cc639b2844 for group hdfs_archiver_group; will retry join-group
2026-01-20 20:46:19,736 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: [Error 79] MemberIdRequiredError
2026-01-20 20:46:19,737 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-20 20:46:23,054 - kafka.coordinator - INFO - Successfully joined group hdfs_archiver_group <Generation 11 (member_id: kafka-python-2.3.0-1d9d9211-1e8d-4aa6-baf6-07cc639b2844, protocol: range)>
2026-01-20 20:46:23,070 - kafka.coordinator - INFO - Elected group leader -- performing partition assignments using range
2026-01-20 20:46:23,164 - kafka.consumer.subscription_state - INFO - Updated partition assignment: [TopicPartition(topic='example_topic', partition=0)]
2026-01-20 20:46:23,169 - kafka.coordinator.consumer - INFO - Setting newly assigned partitions {TopicPartition(topic='example_topic', partition=0)} for group hdfs_archiver_group
2026-01-20 20:46:23,189 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connecting> [IPv6 ('::1', 9098, 0, 0)]>: connecting to localhost:9098 [('::1', 9098, 0, 0) IPv6]
2026-01-20 20:46:23,192 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Connection complete.
2026-01-20 20:46:23,240 - __main__ - INFO - Trigger write: 22 msgs (Timeout: False, Full: True)
2026-01-20 20:46:23,252 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 20:46:23,328 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_20_46_23_22.json'.
2026-01-20 20:46:23,347 - __main__ - ERROR - Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-20 20:47:29,826 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 20:47:29,844 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 20:47:29,965 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_20_47_29_9.json'.
2026-01-20 20:47:30,052 - __main__ - ERROR - Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-20 20:48:32,480 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 20:48:32,495 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 20:48:32,526 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_20_48_32_9.json'.
2026-01-20 20:48:32,579 - __main__ - ERROR - Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-20 20:49:38,347 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 20:49:38,350 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 20:49:38,434 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_20_49_38_9.json'.
2026-01-20 20:49:38,572 - __main__ - ERROR - Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-20 20:50:42,868 - __main__ - INFO - Trigger write: 7 msgs (Timeout: True, Full: False)
2026-01-20 20:50:42,904 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 20:50:43,002 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_20_50_42_7.json'.
2026-01-20 20:50:43,057 - __main__ - ERROR - Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-20 20:51:40,629 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-20 20:51:40,677 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 20:51:40,776 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_20_51_40_10.json'.
2026-01-20 20:51:40,833 - __main__ - ERROR - Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-20 20:52:45,185 - __main__ - INFO - Trigger write: 7 msgs (Timeout: True, Full: False)
2026-01-20 20:52:45,195 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 20:52:45,406 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_20_52_45_7.json'.
2026-01-20 20:52:45,443 - __main__ - ERROR - Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-20 20:53:45,652 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 20:53:45,702 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 20:53:45,997 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_20_53_45_8.json'.
2026-01-20 20:53:46,059 - __main__ - ERROR - Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-20 20:54:46,437 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 20:54:46,465 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 20:54:46,531 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_20_54_46_8.json'.
2026-01-20 20:54:46,577 - __main__ - ERROR - Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-20 20:55:34,373 - __main__ - INFO - Consumer stopped by user.
2026-01-20 20:55:34,377 - __main__ - INFO - Đang ghi dữ liệu còn sót lại trước khi tắt...
2026-01-20 20:55:34,379 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 20:55:34,484 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_20_55_34_6.json'.
2026-01-20 20:55:34,522 - __main__ - ERROR - Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-20 20:55:34,522 - kafka.coordinator.heartbeat - INFO - Stopping heartbeat thread
2026-01-20 20:55:34,522 - kafka.coordinator - INFO - Leaving consumer group hdfs_archiver_group (member kafka-python-2.3.0-1d9d9211-1e8d-4aa6-baf6-07cc639b2844).
2026-01-20 20:55:34,538 - kafka.coordinator - INFO - LeaveGroup request for group hdfs_archiver_group returned successfully
2026-01-20 20:55:34,538 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-20 20:55:34,541 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-20 20:55:34,543 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Closing connection. 
2026-01-20 20:55:34,545 - kafka.consumer.fetcher - INFO - Fetch to node 2 failed: Cancelled: <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>
2026-01-20 20:55:34,548 - __main__ - INFO - Consumer closed.
2026-01-20 21:14:33,270 - __main__ - INFO - Khởi động Consumer... Batch Size: 10, Timeout: 60s
2026-01-20 21:14:33,288 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-1 host=localhost:9098 <connecting> [IPv6 ('::1', 9098, 0, 0)]>: connecting to localhost:9098 [('::1', 9098, 0, 0) IPv6]
2026-01-20 21:14:33,376 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-1 host=localhost:9098 <checking_api_versions_recv> [IPv6 ('::1', 9098, 0, 0)]>: Broker version identified as 2.6
2026-01-20 21:14:33,377 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-1 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Connection complete.
2026-01-20 21:14:33,381 - kafka.consumer.subscription_state - INFO - Updating subscribed topics to: ('example_topic',)
2026-01-20 21:14:33,384 - hdfs.client - INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
2026-01-20 21:14:33,386 - __main__ - INFO - Kết nối HDFS thành công tại: http://localhost:9870
2026-01-20 21:14:33,461 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=3 host=localhost:9099 <connecting> [IPv6 ('::1', 9099, 0, 0)]>: connecting to localhost:9099 [('::1', 9099, 0, 0) IPv6]
2026-01-20 21:14:33,466 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=3 host=localhost:9099 <connected> [IPv6 ('::1', 9099, 0, 0)]>: Connection complete.
2026-01-20 21:14:33,466 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-1 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Closing connection. 
2026-01-20 21:14:33,705 - kafka.cluster - INFO - Coordinator for group/hdfs_archiver_group is BrokerMetadata(nodeId='coordinator-1', host='localhost', port=9097, rack=None)
2026-01-20 21:14:33,712 - kafka.coordinator - INFO - Discovered coordinator coordinator-1 for group hdfs_archiver_group
2026-01-20 21:14:33,712 - kafka.coordinator.heartbeat - INFO - Starting new heartbeat thread
2026-01-20 21:14:33,732 - kafka.coordinator.consumer - INFO - Revoking previously assigned partitions set() for group hdfs_archiver_group
2026-01-20 21:14:33,746 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: NodeNotReadyError: coordinator-1
2026-01-20 21:14:33,748 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-20 21:14:33,750 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-20 21:14:33,861 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-20 21:14:34,071 - kafka.coordinator - INFO - Received member id kafka-python-2.3.0-0d2b1879-3ce0-490f-95b7-d43dc3838c3c for group hdfs_archiver_group; will retry join-group
2026-01-20 21:14:34,073 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: [Error 79] MemberIdRequiredError
2026-01-20 21:14:34,073 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-20 21:14:37,552 - kafka.coordinator - INFO - Successfully joined group hdfs_archiver_group <Generation 13 (member_id: kafka-python-2.3.0-0d2b1879-3ce0-490f-95b7-d43dc3838c3c, protocol: range)>
2026-01-20 21:14:37,563 - kafka.coordinator - INFO - Elected group leader -- performing partition assignments using range
2026-01-20 21:14:38,134 - kafka.consumer.subscription_state - INFO - Updated partition assignment: [TopicPartition(topic='example_topic', partition=0)]
2026-01-20 21:14:38,134 - kafka.coordinator.consumer - INFO - Setting newly assigned partitions {TopicPartition(topic='example_topic', partition=0)} for group hdfs_archiver_group
2026-01-20 21:14:38,191 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connecting> [IPv6 ('::1', 9098, 0, 0)]>: connecting to localhost:9098 [('::1', 9098, 0, 0) IPv6]
2026-01-20 21:14:38,194 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Connection complete.
2026-01-20 21:14:38,381 - __main__ - INFO - Trigger write: 18 msgs (Timeout: False, Full: True)
2026-01-20 21:14:38,383 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:14:51,838 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_14_38_18.json'.
2026-01-20 21:14:51,915 - __main__ - ERROR - Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-20 21:15:50,512 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-20 21:15:50,528 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:15:50,841 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_15_50_10.json'.
2026-01-20 21:15:50,915 - __main__ - ERROR - Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-20 21:16:59,566 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 21:16:59,582 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:16:59,770 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_16_59_9.json'.
2026-01-20 21:16:59,810 - __main__ - ERROR - Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-20 21:18:04,093 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 21:18:04,131 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:18:04,350 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_18_04_8.json'.
2026-01-20 21:18:04,485 - __main__ - ERROR - Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-20 21:19:09,747 - __main__ - INFO - Trigger write: 7 msgs (Timeout: True, Full: False)
2026-01-20 21:19:09,764 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:19:09,811 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_19_09_7.json'.
2026-01-20 21:19:09,856 - __main__ - ERROR - Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-20 21:20:11,635 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 21:20:11,654 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:20:11,895 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_20_11_8.json'.
2026-01-20 21:20:11,982 - __main__ - ERROR - Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-20 21:21:12,999 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 21:21:13,028 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:21:13,402 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_21_13_8.json'.
2026-01-20 21:21:13,442 - __main__ - ERROR - Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-20 21:22:15,525 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 21:22:15,527 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:22:15,592 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_22_15_8.json'.
2026-01-20 21:22:15,696 - __main__ - ERROR - Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-20 21:23:16,961 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 21:23:16,976 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:23:17,098 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_23_16_8.json'.
2026-01-20 21:23:20,116 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_23_16_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_23_16_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:23:20,600 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_23_16_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:24:19,799 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-20 21:24:19,812 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:24:19,962 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_24_19_10.json'.
2026-01-20 21:24:23,008 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_24_19_10.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_24_19_10.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:24:23,106 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_24_19_10.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:25:24,290 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 21:25:24,297 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:25:24,350 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_25_24_9.json'.
2026-01-20 21:25:27,175 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_25_24_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_25_24_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:25:27,192 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_25_24_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:26:27,714 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 21:26:27,756 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:26:28,046 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_26_27_8.json'.
2026-01-20 21:26:31,013 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_26_27_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_26_27_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:26:31,021 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_26_27_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:27:31,421 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 21:27:31,454 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:27:31,928 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_27_31_8.json'.
2026-01-20 21:27:34,908 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_27_31_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_27_31_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:27:34,962 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_27_31_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:28:38,976 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 21:28:38,994 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:28:39,154 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_28_38_8.json'.
2026-01-20 21:28:42,030 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_28_38_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_28_38_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:28:42,040 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_28_38_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:29:44,441 - __main__ - INFO - Trigger write: 7 msgs (Timeout: True, Full: False)
2026-01-20 21:29:44,476 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:29:44,655 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_29_44_7.json'.
2026-01-20 21:29:47,597 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_29_44_7.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_29_44_7.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:29:47,613 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_29_44_7.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:30:48,101 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 21:30:48,123 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:30:48,222 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_30_48_9.json'.
2026-01-20 21:30:51,075 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_30_48_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_30_48_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:30:51,140 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_30_48_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:31:54,741 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 21:31:54,762 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:31:54,965 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_31_54_9.json'.
2026-01-20 21:31:57,932 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_31_54_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_31_54_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:31:57,962 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_31_54_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:32:58,401 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 21:32:58,408 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:32:58,523 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_32_58_8.json'.
2026-01-20 21:33:01,420 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_32_58_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_32_58_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:33:01,433 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_32_58_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:34:02,203 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 21:34:02,214 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:34:02,336 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_34_02_9.json'.
2026-01-20 21:34:05,197 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_34_02_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_34_02_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:34:05,212 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_34_02_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:35:05,856 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 21:35:05,875 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:35:05,975 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_35_05_8.json'.
2026-01-20 21:35:08,965 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_35_05_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_35_05_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:35:09,044 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_35_05_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:36:12,723 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 21:36:12,810 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:36:13,081 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_36_12_9.json'.
2026-01-20 21:36:16,086 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_36_12_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_36_12_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:36:16,147 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_36_12_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:37:17,366 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 21:37:17,374 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:37:17,460 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_37_17_8.json'.
2026-01-20 21:37:20,372 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_37_17_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_37_17_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:37:20,395 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_37_17_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:38:21,841 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 21:38:21,854 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:38:21,961 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_38_21_8.json'.
2026-01-20 21:38:24,836 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_38_21_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_38_21_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:38:24,858 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_38_21_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:39:24,524 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-20 21:39:24,542 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:39:24,691 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_39_24_10.json'.
2026-01-20 21:39:27,591 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_39_24_10.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_39_24_10.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:39:27,702 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_39_24_10.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:40:34,203 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 21:40:34,219 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:40:34,340 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_40_34_8.json'.
2026-01-20 21:40:37,504 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_40_34_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_40_34_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:40:37,581 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_40_34_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:41:38,091 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 21:41:38,116 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:41:38,350 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_41_38_9.json'.
2026-01-20 21:41:41,399 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_41_38_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_41_38_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:41:41,444 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_41_38_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:42:42,004 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 21:42:42,019 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:42:42,139 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_42_42_8.json'.
2026-01-20 21:42:45,177 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_42_42_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_42_42_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:42:45,197 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_42_42_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:43:45,342 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 21:43:45,368 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:43:45,526 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_43_45_9.json'.
2026-01-20 21:43:48,709 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_43_45_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_43_45_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:43:48,832 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_43_45_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:44:24,023 - __main__ - INFO - Consumer stopped by user.
2026-01-20 21:44:24,031 - __main__ - INFO - Đang ghi dữ liệu còn sót lại trước khi tắt...
2026-01-20 21:44:24,033 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:44:24,114 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_44_24_5.json'.
2026-01-20 21:44:26,928 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_44_24_5.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_44_24_5.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:44:26,962 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_44_24_5.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:44:27,013 - kafka.coordinator.heartbeat - INFO - Stopping heartbeat thread
2026-01-20 21:44:27,045 - kafka.coordinator - INFO - Leaving consumer group hdfs_archiver_group (member kafka-python-2.3.0-0d2b1879-3ce0-490f-95b7-d43dc3838c3c).
2026-01-20 21:44:27,269 - kafka.coordinator - INFO - LeaveGroup request for group hdfs_archiver_group returned successfully
2026-01-20 21:44:27,285 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=3 host=localhost:9099 <connected> [IPv6 ('::1', 9099, 0, 0)]>: Closing connection. 
2026-01-20 21:44:27,300 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-20 21:44:27,330 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Closing connection. 
2026-01-20 21:44:27,374 - __main__ - INFO - Consumer closed.
2026-01-20 21:44:33,332 - __main__ - INFO - Khởi động Consumer... Batch Size: 10, Timeout: 60s
2026-01-20 21:44:33,406 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-2 host=localhost:9099 <connecting> [IPv6 ('::1', 9099, 0, 0)]>: connecting to localhost:9099 [('::1', 9099, 0, 0) IPv6]
2026-01-20 21:44:33,501 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-2 host=localhost:9099 <checking_api_versions_recv> [IPv6 ('::1', 9099, 0, 0)]>: Broker version identified as 2.6
2026-01-20 21:44:33,509 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-2 host=localhost:9099 <connected> [IPv6 ('::1', 9099, 0, 0)]>: Connection complete.
2026-01-20 21:44:33,528 - kafka.consumer.subscription_state - INFO - Updating subscribed topics to: ('example_topic',)
2026-01-20 21:44:33,533 - hdfs.client - INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
2026-01-20 21:44:33,564 - __main__ - INFO - Kết nối HDFS thành công tại: http://localhost:9870
2026-01-20 21:44:33,620 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=3 host=localhost:9099 <connecting> [IPv6 ('::1', 9099, 0, 0)]>: connecting to localhost:9099 [('::1', 9099, 0, 0) IPv6]
2026-01-20 21:44:33,643 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=3 host=localhost:9099 <connected> [IPv6 ('::1', 9099, 0, 0)]>: Connection complete.
2026-01-20 21:44:33,665 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-2 host=localhost:9099 <connected> [IPv6 ('::1', 9099, 0, 0)]>: Closing connection. 
2026-01-20 21:44:33,852 - kafka.cluster - INFO - Coordinator for group/hdfs_archiver_group is BrokerMetadata(nodeId='coordinator-1', host='localhost', port=9097, rack=None)
2026-01-20 21:44:33,878 - kafka.coordinator - INFO - Discovered coordinator coordinator-1 for group hdfs_archiver_group
2026-01-20 21:44:33,880 - kafka.coordinator.heartbeat - INFO - Starting new heartbeat thread
2026-01-20 21:44:33,938 - kafka.coordinator.consumer - INFO - Revoking previously assigned partitions set() for group hdfs_archiver_group
2026-01-20 21:44:33,999 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: NodeNotReadyError: coordinator-1
2026-01-20 21:44:34,037 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-20 21:44:34,069 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-20 21:44:34,296 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-20 21:44:34,420 - kafka.coordinator - INFO - Received member id kafka-python-2.3.0-424154ea-c6d9-46a3-817d-df677a1c6190 for group hdfs_archiver_group; will retry join-group
2026-01-20 21:44:34,443 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: [Error 79] MemberIdRequiredError
2026-01-20 21:44:34,491 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-20 21:44:37,880 - kafka.coordinator - INFO - Successfully joined group hdfs_archiver_group <Generation 15 (member_id: kafka-python-2.3.0-424154ea-c6d9-46a3-817d-df677a1c6190, protocol: range)>
2026-01-20 21:44:37,910 - kafka.coordinator - INFO - Elected group leader -- performing partition assignments using range
2026-01-20 21:44:38,014 - kafka.consumer.subscription_state - INFO - Updated partition assignment: [TopicPartition(topic='example_topic', partition=0)]
2026-01-20 21:44:38,036 - kafka.coordinator.consumer - INFO - Setting newly assigned partitions {TopicPartition(topic='example_topic', partition=0)} for group hdfs_archiver_group
2026-01-20 21:44:38,071 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connecting> [IPv6 ('::1', 9098, 0, 0)]>: connecting to localhost:9098 [('::1', 9098, 0, 0) IPv6]
2026-01-20 21:44:38,125 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Connection complete.
2026-01-20 21:45:01,158 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-20 21:45:01,175 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:45:01,340 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_45_01_10.json'.
2026-01-20 21:45:04,237 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_45_01_10.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_45_01_10.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:45:04,263 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_45_01_10.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:46:06,457 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 21:46:06,464 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:46:06,634 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_46_06_9.json'.
2026-01-20 21:46:09,503 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_46_06_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_46_06_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:46:09,534 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_46_06_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:46:20,301 - __main__ - INFO - Consumer stopped by user.
2026-01-20 21:46:20,320 - __main__ - INFO - Đang ghi dữ liệu còn sót lại trước khi tắt...
2026-01-20 21:46:20,335 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:46:20,436 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_46_20_2.json'.
2026-01-20 21:46:23,289 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_46_20_2.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_46_20_2.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:46:23,303 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_46_20_2.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:46:23,309 - kafka.coordinator.heartbeat - INFO - Stopping heartbeat thread
2026-01-20 21:46:23,311 - kafka.coordinator - INFO - Leaving consumer group hdfs_archiver_group (member kafka-python-2.3.0-424154ea-c6d9-46a3-817d-df677a1c6190).
2026-01-20 21:46:23,423 - kafka.coordinator - INFO - LeaveGroup request for group hdfs_archiver_group returned successfully
2026-01-20 21:46:23,479 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=3 host=localhost:9099 <connected> [IPv6 ('::1', 9099, 0, 0)]>: Closing connection. 
2026-01-20 21:46:23,531 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-20 21:46:23,564 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Closing connection. 
2026-01-20 21:46:23,600 - __main__ - INFO - Consumer closed.
2026-01-20 21:46:34,106 - __main__ - INFO - Khởi động Consumer... Batch Size: 10, Timeout: 60s
2026-01-20 21:46:34,131 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-20 21:46:34,224 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9097 <checking_api_versions_recv> [IPv6 ('::1', 9097, 0, 0)]>: Broker version identified as 2.6
2026-01-20 21:46:34,233 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-20 21:46:34,251 - kafka.consumer.subscription_state - INFO - Updating subscribed topics to: ('example_topic',)
2026-01-20 21:46:34,252 - hdfs.client - INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
2026-01-20 21:46:34,265 - __main__ - INFO - Kết nối HDFS thành công tại: http://localhost:9870
2026-01-20 21:46:34,296 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=3 host=localhost:9099 <connecting> [IPv6 ('::1', 9099, 0, 0)]>: connecting to localhost:9099 [('::1', 9099, 0, 0) IPv6]
2026-01-20 21:46:34,302 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=3 host=localhost:9099 <connected> [IPv6 ('::1', 9099, 0, 0)]>: Connection complete.
2026-01-20 21:46:34,316 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-20 21:46:34,442 - kafka.cluster - INFO - Coordinator for group/hdfs_archiver_group is BrokerMetadata(nodeId='coordinator-1', host='localhost', port=9097, rack=None)
2026-01-20 21:46:34,457 - kafka.coordinator - INFO - Discovered coordinator coordinator-1 for group hdfs_archiver_group
2026-01-20 21:46:34,458 - kafka.coordinator.heartbeat - INFO - Starting new heartbeat thread
2026-01-20 21:46:34,485 - kafka.coordinator.consumer - INFO - Revoking previously assigned partitions set() for group hdfs_archiver_group
2026-01-20 21:46:34,496 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: NodeNotReadyError: coordinator-1
2026-01-20 21:46:34,504 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-20 21:46:34,519 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-20 21:46:34,678 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-20 21:46:34,702 - kafka.coordinator - INFO - Received member id kafka-python-2.3.0-7195f067-1279-4020-a5bd-4f18ece3af72 for group hdfs_archiver_group; will retry join-group
2026-01-20 21:46:34,717 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: [Error 79] MemberIdRequiredError
2026-01-20 21:46:34,719 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-20 21:46:38,056 - kafka.coordinator - INFO - Successfully joined group hdfs_archiver_group <Generation 17 (member_id: kafka-python-2.3.0-7195f067-1279-4020-a5bd-4f18ece3af72, protocol: range)>
2026-01-20 21:46:38,064 - kafka.coordinator - INFO - Elected group leader -- performing partition assignments using range
2026-01-20 21:46:38,159 - kafka.consumer.subscription_state - INFO - Updated partition assignment: [TopicPartition(topic='example_topic', partition=0)]
2026-01-20 21:46:38,175 - kafka.coordinator.consumer - INFO - Setting newly assigned partitions {TopicPartition(topic='example_topic', partition=0)} for group hdfs_archiver_group
2026-01-20 21:46:38,211 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connecting> [IPv6 ('::1', 9098, 0, 0)]>: connecting to localhost:9098 [('::1', 9098, 0, 0) IPv6]
2026-01-20 21:46:38,266 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Connection complete.
2026-01-20 21:47:19,102 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-20 21:47:19,128 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:47:19,240 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_47_19_10.json'.
2026-01-20 21:47:22,119 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_47_19_10.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_47_19_10.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:47:22,138 - __main__ - ERROR - Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages%5C2026%5C01%5C20%5Cbatdongsan_21_47_19_10.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=false&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-20 21:48:26,607 - __main__ - INFO - Trigger write: 7 msgs (Timeout: True, Full: False)
2026-01-20 21:48:26,627 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:48:26,827 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_48_26_7.json'.
2026-01-20 21:48:36,991 - __main__ - INFO - >>> Đã lưu 7 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_21_48_26_7.json
2026-01-20 21:49:37,191 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 21:49:37,208 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:49:37,318 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_49_37_9.json'.
2026-01-20 21:49:41,734 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_21_49_37_9.json
2026-01-20 21:50:41,902 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 21:50:41,933 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:50:42,106 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_50_41_9.json'.
2026-01-20 21:50:44,593 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_21_50_41_9.json
2026-01-20 21:51:47,530 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 21:51:47,580 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:51:47,730 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_51_47_9.json'.
2026-01-20 21:51:53,311 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_21_51_47_9.json
2026-01-20 21:52:54,395 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 21:52:54,426 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:52:54,537 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_52_54_9.json'.
2026-01-20 21:52:59,012 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_21_52_54_9.json
2026-01-20 21:54:03,039 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 21:54:03,063 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:54:03,169 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_54_03_9.json'.
2026-01-20 21:54:07,019 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_21_54_03_9.json
2026-01-20 21:55:07,688 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 21:55:07,698 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:55:07,791 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_55_07_8.json'.
2026-01-20 21:55:12,178 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_21_55_07_8.json
2026-01-20 21:56:11,379 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-20 21:56:11,384 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:56:11,459 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_56_11_10.json'.
2026-01-20 21:56:12,896 - __main__ - INFO - >>> Đã lưu 10 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_21_56_11_10.json
2026-01-20 21:57:17,130 - __main__ - INFO - Trigger write: 7 msgs (Timeout: True, Full: False)
2026-01-20 21:57:17,154 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:57:17,250 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_57_17_7.json'.
2026-01-20 21:57:23,029 - __main__ - INFO - >>> Đã lưu 7 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_21_57_17_7.json
2026-01-20 21:58:23,682 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 21:58:23,713 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:58:23,866 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_58_23_9.json'.
2026-01-20 21:58:29,043 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_21_58_23_9.json
2026-01-20 21:59:29,209 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 21:59:29,216 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 21:59:29,277 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_21_59_29_8.json'.
2026-01-20 21:59:30,524 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_21_59_29_8.json
2026-01-20 22:00:30,766 - __main__ - INFO - Trigger write: 10 msgs (Timeout: True, Full: True)
2026-01-20 22:00:30,778 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:00:30,849 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_00_30_10.json'.
2026-01-20 22:00:33,874 - __main__ - INFO - >>> Đã lưu 10 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_00_30_10.json
2026-01-20 22:01:37,076 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:01:37,087 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:01:37,151 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_01_37_8.json'.
2026-01-20 22:01:38,994 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_01_37_8.json
2026-01-20 22:02:39,393 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:02:39,404 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:02:39,457 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_02_39_9.json'.
2026-01-20 22:02:41,189 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_02_39_9.json
2026-01-20 22:03:47,964 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:03:47,977 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:03:48,136 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_03_47_8.json'.
2026-01-20 22:03:52,940 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_03_47_8.json
2026-01-20 22:04:53,317 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:04:53,326 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:04:53,419 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_04_53_9.json'.
2026-01-20 22:04:56,737 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_04_53_9.json
2026-01-20 22:05:56,970 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:05:56,983 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:05:57,058 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_05_56_8.json'.
2026-01-20 22:06:00,864 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_05_56_8.json
2026-01-20 22:07:01,000 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:07:01,007 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:07:01,116 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_07_01_9.json'.
2026-01-20 22:07:02,606 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_07_01_9.json
2026-01-20 22:08:02,714 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:08:02,736 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:08:02,823 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_08_02_9.json'.
2026-01-20 22:08:05,592 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_08_02_9.json
2026-01-20 22:09:06,312 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:09:06,322 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:09:06,470 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_09_06_8.json'.
2026-01-20 22:09:11,047 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_09_06_8.json
2026-01-20 22:10:05,439 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-20 22:10:05,456 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:10:05,530 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_10_05_10.json'.
2026-01-20 22:10:06,619 - __main__ - INFO - >>> Đã lưu 10 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_10_05_10.json
2026-01-20 22:11:09,937 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:11:09,955 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:11:10,029 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_11_09_8.json'.
2026-01-20 22:11:12,776 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_11_09_8.json
2026-01-20 22:12:13,424 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:12:13,446 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:12:13,530 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_12_13_8.json'.
2026-01-20 22:12:18,121 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_12_13_8.json
2026-01-20 22:13:18,281 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:13:18,300 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:13:18,381 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_13_18_9.json'.
2026-01-20 22:13:20,945 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_13_18_9.json
2026-01-20 22:14:24,427 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:14:24,433 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:14:24,513 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_14_24_9.json'.
2026-01-20 22:14:29,089 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_14_24_9.json
2026-01-20 22:15:20,957 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-20 22:15:21,025 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:15:21,375 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_15_21_10.json'.
2026-01-20 22:15:29,963 - __main__ - INFO - >>> Đã lưu 10 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_15_21_10.json
2026-01-20 22:16:29,553 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-20 22:16:29,562 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:16:29,678 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_16_29_10.json'.
2026-01-20 22:16:32,432 - __main__ - INFO - >>> Đã lưu 10 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_16_29_10.json
2026-01-20 22:17:38,926 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:17:38,959 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:17:39,157 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_17_38_8.json'.
2026-01-20 22:17:43,989 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_17_38_8.json
2026-01-20 22:18:40,690 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-20 22:18:40,697 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:18:40,772 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_18_40_10.json'.
2026-01-20 22:18:44,445 - __main__ - INFO - >>> Đã lưu 10 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_18_40_10.json
2026-01-20 22:19:50,328 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:19:50,339 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:19:50,533 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_19_50_8.json'.
2026-01-20 22:19:51,331 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_19_50_8.json
2026-01-20 22:20:55,011 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:20:55,032 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:20:55,116 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_20_55_8.json'.
2026-01-20 22:20:58,276 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_20_55_8.json
2026-01-20 22:21:59,208 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:21:59,224 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:21:59,393 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_21_59_9.json'.
2026-01-20 22:22:01,165 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_21_59_9.json
2026-01-20 22:23:01,810 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:23:01,831 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:23:01,944 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_23_01_9.json'.
2026-01-20 22:23:02,668 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_23_01_9.json
2026-01-20 22:24:06,916 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:24:06,959 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:24:07,139 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_24_06_8.json'.
2026-01-20 22:24:08,624 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_24_06_8.json
2026-01-20 22:25:12,357 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:25:12,382 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:25:12,509 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_25_12_8.json'.
2026-01-20 22:25:16,866 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_25_12_8.json
2026-01-20 22:26:19,600 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:26:19,611 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:26:19,768 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_26_19_8.json'.
2026-01-20 22:26:21,174 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_26_19_8.json
2026-01-20 22:27:24,124 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:27:24,145 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:27:24,256 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_27_24_8.json'.
2026-01-20 22:27:29,264 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_27_24_8.json
2026-01-20 22:28:29,868 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:28:29,883 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:28:29,967 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_28_29_8.json'.
2026-01-20 22:28:33,003 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_28_29_8.json
2026-01-20 22:29:33,540 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:29:33,554 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:29:33,656 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_29_33_9.json'.
2026-01-20 22:29:36,280 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_29_33_9.json
2026-01-20 22:30:38,498 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:30:38,518 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:30:38,636 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_30_38_9.json'.
2026-01-20 22:30:39,099 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_30_38_9.json
2026-01-20 22:31:47,998 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:31:48,011 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:31:48,101 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_31_48_8.json'.
2026-01-20 22:31:49,863 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_31_48_8.json
2026-01-20 22:32:53,347 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:32:53,357 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:32:53,435 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_32_53_9.json'.
2026-01-20 22:32:54,482 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_32_53_9.json
2026-01-20 22:33:57,922 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:33:57,927 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:33:57,997 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_33_57_9.json'.
2026-01-20 22:33:59,894 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_33_57_9.json
2026-01-20 22:35:00,060 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:35:00,070 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:35:00,168 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_35_00_8.json'.
2026-01-20 22:35:01,235 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_35_00_8.json
2026-01-20 22:36:01,947 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:36:01,960 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:36:02,118 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_36_01_9.json'.
2026-01-20 22:36:05,612 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_36_01_9.json
2026-01-20 22:37:08,359 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:37:08,375 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:37:08,467 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_37_08_8.json'.
2026-01-20 22:37:10,245 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_37_08_8.json
2026-01-20 22:38:10,846 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:38:10,866 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:38:11,064 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_38_10_9.json'.
2026-01-20 22:38:13,963 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_38_10_9.json
2026-01-20 22:39:14,721 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:39:14,729 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:39:14,885 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_39_14_9.json'.
2026-01-20 22:39:18,453 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_39_14_9.json
2026-01-20 22:40:18,738 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:40:18,760 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:40:19,033 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_40_18_8.json'.
2026-01-20 22:40:21,772 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_40_18_8.json
2026-01-20 22:41:24,680 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:41:24,695 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:41:24,782 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_41_24_9.json'.
2026-01-20 22:41:26,595 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_41_24_9.json
2026-01-20 22:42:27,213 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:42:27,219 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:42:27,358 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_42_27_9.json'.
2026-01-20 22:42:29,114 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_42_27_9.json
2026-01-20 22:43:33,087 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:43:33,094 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:43:33,143 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_43_33_9.json'.
2026-01-20 22:43:36,334 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_43_33_9.json
2026-01-20 22:44:37,844 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:44:37,850 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:44:37,930 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_44_37_8.json'.
2026-01-20 22:44:39,849 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_44_37_8.json
2026-01-20 22:45:44,784 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:45:44,791 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:45:44,902 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_45_44_9.json'.
2026-01-20 22:45:49,103 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_45_44_9.json
2026-01-20 22:46:49,775 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:46:49,789 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:46:49,866 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_46_49_9.json'.
2026-01-20 22:46:53,318 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_46_49_9.json
2026-01-20 22:47:54,515 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:47:54,526 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:47:54,641 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_47_54_9.json'.
2026-01-20 22:47:59,356 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_47_54_9.json
2026-01-20 22:49:03,182 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:49:03,199 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:49:03,281 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_49_03_8.json'.
2026-01-20 22:49:05,897 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_49_03_8.json
2026-01-20 22:50:06,088 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:50:06,092 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:50:06,145 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_50_06_8.json'.
2026-01-20 22:50:09,333 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_50_06_8.json
2026-01-20 22:51:10,849 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:51:10,857 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:51:10,919 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_51_10_9.json'.
2026-01-20 22:51:14,043 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_51_10_9.json
2026-01-20 22:52:20,524 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:52:20,529 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:52:20,595 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_52_20_8.json'.
2026-01-20 22:52:21,381 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_52_20_8.json
2026-01-20 22:53:22,969 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-20 22:53:22,988 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:53:23,129 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_53_22_10.json'.
2026-01-20 22:53:28,381 - __main__ - INFO - >>> Đã lưu 10 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_53_22_10.json
2026-01-20 22:54:29,875 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:54:29,880 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:54:30,030 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_54_29_8.json'.
2026-01-20 22:54:30,853 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_54_29_8.json
2026-01-20 22:55:30,913 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 22:55:30,947 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:55:31,277 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_55_30_8.json'.
2026-01-20 22:55:33,438 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_55_30_8.json
2026-01-20 22:56:35,712 - __main__ - INFO - Trigger write: 7 msgs (Timeout: True, Full: False)
2026-01-20 22:56:35,807 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:56:36,020 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_56_35_7.json'.
2026-01-20 22:56:38,728 - __main__ - INFO - >>> Đã lưu 7 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_56_35_7.json
2026-01-20 22:57:39,760 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:57:39,774 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:57:40,016 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_57_39_9.json'.
2026-01-20 22:57:43,322 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_57_39_9.json
2026-01-20 22:58:44,627 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:58:44,666 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:58:44,809 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_58_44_9.json'.
2026-01-20 22:58:52,336 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_58_44_9.json
2026-01-20 22:59:52,741 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 22:59:52,758 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 22:59:52,868 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_22_59_52_9.json'.
2026-01-20 22:59:58,567 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_22_59_52_9.json
2026-01-20 23:00:59,381 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:00:59,421 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 23:00:59,631 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_23_00_59_9.json'.
2026-01-20 23:01:07,578 - __main__ - INFO - >>> Đã lưu 9 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_23_00_59_9.json
2026-01-20 23:02:01,769 - __main__ - INFO - Consumer stopped by user.
2026-01-20 23:02:01,854 - __main__ - INFO - Đang ghi dữ liệu còn sót lại trước khi tắt...
2026-01-20 23:02:01,956 - hdfs.client - INFO - Fetching status for '/data/kafka_messages\\2026\\01\\20'.
2026-01-20 23:02:02,065 - hdfs.client - INFO - Writing to '/data/kafka_messages\\2026\\01\\20\\batdongsan_23_02_01_8.json'.
2026-01-20 23:02:05,061 - __main__ - INFO - >>> Đã lưu 8 tin vào HDFS: /data/kafka_messages\2026\01\20\batdongsan_23_02_01_8.json
2026-01-20 23:02:05,100 - kafka.coordinator.heartbeat - INFO - Stopping heartbeat thread
2026-01-20 23:02:05,142 - kafka.coordinator - INFO - Leaving consumer group hdfs_archiver_group (member kafka-python-2.3.0-7195f067-1279-4020-a5bd-4f18ece3af72).
2026-01-20 23:02:05,308 - kafka.coordinator - INFO - LeaveGroup request for group hdfs_archiver_group returned successfully
2026-01-20 23:02:05,323 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=3 host=localhost:9099 <connected> [IPv6 ('::1', 9099, 0, 0)]>: Closing connection. 
2026-01-20 23:02:05,348 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-20 23:02:05,381 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Closing connection. 
2026-01-20 23:02:05,385 - __main__ - INFO - Consumer closed.
2026-01-20 23:02:16,940 - __main__ - INFO - 🚀 Khởi động Consumer... Batch Size: 10
2026-01-20 23:02:17,026 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-2 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-20 23:02:17,084 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-2 host=localhost:9097 <checking_api_versions_recv> [IPv6 ('::1', 9097, 0, 0)]>: Broker version identified as 2.6
2026-01-20 23:02:17,093 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-2 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-20 23:02:17,113 - kafka.consumer.subscription_state - INFO - Updating subscribed topics to: ('example_topic',)
2026-01-20 23:02:17,121 - hdfs.client - INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
2026-01-20 23:02:17,123 - hdfs.client - INFO - Fetching content summary for '/'.
2026-01-20 23:02:17,300 - __main__ - INFO - ✅ Kết nối HDFS thành công tại: http://localhost:9870
2026-01-20 23:02:17,385 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-20 23:02:17,398 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-20 23:02:17,400 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-2 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-20 23:02:17,529 - kafka.cluster - INFO - Coordinator for group/hdfs_archiver_group is BrokerMetadata(nodeId='coordinator-1', host='localhost', port=9097, rack=None)
2026-01-20 23:02:17,548 - kafka.coordinator - INFO - Discovered coordinator coordinator-1 for group hdfs_archiver_group
2026-01-20 23:02:17,564 - kafka.coordinator.heartbeat - INFO - Starting new heartbeat thread
2026-01-20 23:02:17,584 - kafka.coordinator.consumer - INFO - Revoking previously assigned partitions set() for group hdfs_archiver_group
2026-01-20 23:02:17,603 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: NodeNotReadyError: coordinator-1
2026-01-20 23:02:17,629 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-20 23:02:17,644 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-20 23:02:17,778 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-20 23:02:17,827 - kafka.coordinator - INFO - Received member id kafka-python-2.3.0-93ce9e36-0510-4578-bc29-07d325c7cfe2 for group hdfs_archiver_group; will retry join-group
2026-01-20 23:02:17,854 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: [Error 79] MemberIdRequiredError
2026-01-20 23:02:17,867 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-20 23:02:21,463 - kafka.coordinator - INFO - Successfully joined group hdfs_archiver_group <Generation 19 (member_id: kafka-python-2.3.0-93ce9e36-0510-4578-bc29-07d325c7cfe2, protocol: range)>
2026-01-20 23:02:21,485 - kafka.coordinator - INFO - Elected group leader -- performing partition assignments using range
2026-01-20 23:02:21,592 - kafka.consumer.subscription_state - INFO - Updated partition assignment: [TopicPartition(topic='example_topic', partition=0)]
2026-01-20 23:02:21,631 - kafka.coordinator.consumer - INFO - Setting newly assigned partitions {TopicPartition(topic='example_topic', partition=0)} for group hdfs_archiver_group
2026-01-20 23:02:21,802 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connecting> [IPv6 ('::1', 9098, 0, 0)]>: connecting to localhost:9098 [('::1', 9098, 0, 0) IPv6]
2026-01-20 23:02:21,817 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Connection complete.
2026-01-20 23:02:21,874 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-20 23:02:21,904 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:02:22,007 - hdfs.client - INFO - Creating directories to '/data/kafka_messages/2026/01/20'.
2026-01-20 23:02:22,266 - __main__ - INFO - Created HDFS directory: /data/kafka_messages/2026/01/20
2026-01-20 23:02:22,278 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_02_21_10.json'.
2026-01-20 23:02:23,575 - __main__ - INFO - 💾 Đã lưu 10 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_02_21_10.json
2026-01-20 23:03:28,847 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:03:28,865 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:03:28,987 - hdfs.client - INFO - Creating directories to '/data/kafka_messages/2026/01/20'.
2026-01-20 23:03:29,225 - __main__ - INFO - Created HDFS directory: /data/kafka_messages/2026/01/20
2026-01-20 23:03:29,238 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_03_28_8.json'.
2026-01-20 23:03:34,251 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_03_28_8.json
2026-01-20 23:04:34,590 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:04:34,608 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:04:34,644 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_04_34_9.json'.
2026-01-20 23:04:42,104 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_04_34_9.json
2026-01-20 23:05:43,367 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:05:43,378 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:05:43,547 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_05_43_8.json'.
2026-01-20 23:05:46,830 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_05_43_8.json
2026-01-20 23:06:46,970 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:06:46,980 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:06:47,076 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_06_46_8.json'.
2026-01-20 23:06:52,448 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_06_46_8.json
2026-01-20 23:07:53,148 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:07:53,160 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:07:53,348 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_07_53_9.json'.
2026-01-20 23:07:56,852 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_07_53_9.json
2026-01-20 23:08:57,379 - __main__ - INFO - Trigger write: 10 msgs (Timeout: True, Full: True)
2026-01-20 23:08:57,397 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:08:57,611 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_08_57_10.json'.
2026-01-20 23:08:59,973 - __main__ - INFO - 💾 Đã lưu 10 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_08_57_10.json
2026-01-20 23:10:06,722 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:10:06,750 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:10:06,902 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_10_06_9.json'.
2026-01-20 23:10:09,658 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_10_06_9.json
2026-01-20 23:11:16,032 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:11:16,051 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:11:16,131 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_11_16_9.json'.
2026-01-20 23:11:24,054 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_11_16_9.json
2026-01-20 23:12:25,593 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:12:25,609 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:12:25,836 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_12_25_9.json'.
2026-01-20 23:12:28,131 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_12_25_9.json
2026-01-20 23:13:29,470 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:13:29,517 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:13:29,697 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_13_29_8.json'.
2026-01-20 23:13:35,624 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_13_29_8.json
2026-01-20 23:14:31,790 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-20 23:14:31,827 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:14:31,904 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_14_31_10.json'.
2026-01-20 23:14:37,796 - __main__ - INFO - 💾 Đã lưu 10 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_14_31_10.json
2026-01-20 23:15:40,225 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:15:40,249 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:15:40,449 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_15_40_8.json'.
2026-01-20 23:15:46,900 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_15_40_8.json
2026-01-20 23:16:48,915 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:16:48,920 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:16:49,017 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_16_48_8.json'.
2026-01-20 23:16:51,336 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_16_48_8.json
2026-01-20 23:17:53,114 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:17:53,126 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:17:53,183 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_17_53_9.json'.
2026-01-20 23:17:54,409 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_17_53_9.json
2026-01-20 23:18:57,095 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:18:57,129 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:18:57,225 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_18_57_9.json'.
2026-01-20 23:18:59,210 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_18_57_9.json
2026-01-20 23:19:59,536 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:19:59,576 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:19:59,760 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_19_59_8.json'.
2026-01-20 23:20:02,126 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_19_59_8.json
2026-01-20 23:21:03,578 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:21:03,589 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:21:03,668 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_21_03_9.json'.
2026-01-20 23:21:10,398 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_21_03_9.json
2026-01-20 23:22:10,554 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:22:10,631 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:22:10,961 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_22_10_9.json'.
2026-01-20 23:22:14,000 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_22_10_9.json
2026-01-20 23:23:14,328 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:23:14,343 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:23:14,522 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_23_14_8.json'.
2026-01-20 23:23:22,237 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_23_14_8.json
2026-01-20 23:24:22,552 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:24:22,653 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:24:22,956 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_24_22_9.json'.
2026-01-20 23:24:27,467 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_24_22_9.json
2026-01-20 23:25:28,382 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:25:28,388 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:25:28,500 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_25_28_8.json'.
2026-01-20 23:25:33,863 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_25_28_8.json
2026-01-20 23:26:34,774 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:26:34,790 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:26:34,936 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_26_34_8.json'.
2026-01-20 23:26:38,861 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_26_34_8.json
2026-01-20 23:27:40,873 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:27:40,907 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:27:41,146 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_27_40_8.json'.
2026-01-20 23:27:47,367 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_27_40_8.json
2026-01-20 23:28:48,319 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:28:48,339 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:28:48,569 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_28_48_9.json'.
2026-01-20 23:28:50,571 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_28_48_9.json
2026-01-20 23:29:50,746 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:29:50,789 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:29:50,942 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_29_50_8.json'.
2026-01-20 23:29:59,565 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_29_50_8.json
2026-01-20 23:31:00,006 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:31:00,031 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:31:00,116 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_31_00_9.json'.
2026-01-20 23:31:06,862 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_31_00_9.json
2026-01-20 23:32:07,497 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:32:07,532 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:32:07,720 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_32_07_9.json'.
2026-01-20 23:32:15,225 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_32_07_9.json
2026-01-20 23:33:15,715 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:33:15,732 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:33:15,766 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_33_15_9.json'.
2026-01-20 23:33:18,133 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_33_15_9.json
2026-01-20 23:34:19,693 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:34:19,749 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:34:19,812 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_34_19_9.json'.
2026-01-20 23:34:25,696 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_34_19_9.json
2026-01-20 23:35:26,336 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:35:26,348 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:35:26,382 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_35_26_9.json'.
2026-01-20 23:35:26,902 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_35_26_9.json
2026-01-20 23:36:27,165 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:36:27,183 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:36:27,333 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_36_27_9.json'.
2026-01-20 23:36:31,218 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_36_27_9.json
2026-01-20 23:37:32,104 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:37:32,105 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:37:32,173 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_37_32_9.json'.
2026-01-20 23:37:37,580 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_37_32_9.json
2026-01-20 23:38:37,765 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:38:37,765 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:38:37,867 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_38_37_8.json'.
2026-01-20 23:38:39,204 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_38_37_8.json
2026-01-20 23:39:41,052 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:39:41,053 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:39:41,076 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_39_41_8.json'.
2026-01-20 23:39:44,096 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_39_41_8.json
2026-01-20 23:40:45,099 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:40:45,101 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:40:45,266 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_40_45_8.json'.
2026-01-20 23:40:48,045 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_40_45_8.json
2026-01-20 23:41:49,910 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:41:49,911 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:41:49,954 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_41_49_8.json'.
2026-01-20 23:41:53,038 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_41_49_8.json
2026-01-20 23:42:53,266 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:42:53,283 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:42:53,308 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_42_53_8.json'.
2026-01-20 23:42:56,964 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_42_53_8.json
2026-01-20 23:44:00,328 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:44:00,358 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:44:00,472 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_44_00_9.json'.
2026-01-20 23:44:04,208 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_44_00_9.json
2026-01-20 23:45:07,190 - __main__ - INFO - Trigger write: 7 msgs (Timeout: True, Full: False)
2026-01-20 23:45:07,215 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:45:07,293 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_45_07_7.json'.
2026-01-20 23:45:09,039 - __main__ - INFO - 💾 Đã lưu 7 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_45_07_7.json
2026-01-20 23:46:09,803 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:46:09,848 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:46:10,006 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_46_09_9.json'.
2026-01-20 23:46:10,949 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_46_09_9.json
2026-01-20 23:47:11,331 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-20 23:47:11,333 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:47:11,430 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_47_11_9.json'.
2026-01-20 23:47:13,062 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_47_11_9.json
2026-01-20 23:48:18,096 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:48:18,108 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:48:18,250 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_48_18_8.json'.
2026-01-20 23:48:19,674 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_48_18_8.json
2026-01-20 23:49:22,650 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:49:22,662 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:49:22,732 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_49_22_8.json'.
2026-01-20 23:49:23,923 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/20/batdongsan_23_49_22_8.json
2026-01-20 23:50:24,275 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:50:24,288 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:50:24,379 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_50_24_8.json'.
2026-01-20 23:50:28,628 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 219, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_50_24_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_50_24_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-20 23:50:28,718 - __main__ - ERROR - ❌ Lỗi ghi HDFS: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_50_24_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-20 23:51:29,329 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:51:29,339 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:51:29,471 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_51_29_8.json'.
2026-01-20 23:51:33,777 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 219, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_51_29_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_51_29_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-20 23:51:33,805 - __main__ - ERROR - ❌ Lỗi ghi HDFS: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_51_29_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-20 23:52:34,297 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:52:34,301 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:52:34,364 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_52_34_8.json'.
2026-01-20 23:52:38,587 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 219, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_52_34_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_52_34_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-20 23:52:38,639 - __main__ - ERROR - ❌ Lỗi ghi HDFS: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_52_34_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-20 23:53:39,377 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:53:39,387 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:53:39,427 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_53_39_8.json'.
2026-01-20 23:53:43,656 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 219, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_53_39_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_53_39_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-20 23:53:43,675 - __main__ - ERROR - ❌ Lỗi ghi HDFS: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_53_39_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-20 23:54:43,819 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:54:43,831 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:54:43,889 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_54_43_8.json'.
2026-01-20 23:54:48,006 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 219, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_54_43_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_54_43_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-20 23:54:48,016 - __main__ - ERROR - ❌ Lỗi ghi HDFS: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_54_43_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-20 23:55:48,876 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-20 23:55:49,000 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:55:49,751 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_55_49_8.json'.
2026-01-20 23:55:54,079 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 219, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_55_49_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_55_49_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-20 23:55:54,123 - __main__ - ERROR - ❌ Lỗi ghi HDFS: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_55_49_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-20 23:56:24,059 - __main__ - INFO - 🛑 Consumer stopped by user.
2026-01-20 23:56:24,073 - __main__ - INFO - Đang ghi dữ liệu còn sót lại trước khi tắt...
2026-01-20 23:56:24,080 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/20'.
2026-01-20 23:56:24,192 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/20/batdongsan_23_56_24_5.json'.
2026-01-20 23:56:28,421 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 219, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_56_24_5.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_56_24_5.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-20 23:56:28,462 - __main__ - ERROR - ❌ Lỗi ghi HDFS: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/20/batdongsan_23_56_24_5.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-20 23:56:28,482 - kafka.coordinator.heartbeat - INFO - Stopping heartbeat thread
2026-01-20 23:56:28,585 - kafka.coordinator - INFO - Leaving consumer group hdfs_archiver_group (member kafka-python-2.3.0-93ce9e36-0510-4578-bc29-07d325c7cfe2).
2026-01-20 23:56:28,747 - kafka.coordinator - INFO - LeaveGroup request for group hdfs_archiver_group returned successfully
2026-01-20 23:56:28,759 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-20 23:56:28,790 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-20 23:56:28,821 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Closing connection. 
2026-01-20 23:56:28,853 - __main__ - INFO - Consumer closed.
2026-01-21 00:21:10,497 - __main__ - INFO - 🚀 Khởi động Consumer... Batch Size: 10
2026-01-21 00:21:10,575 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-2 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-21 00:21:10,751 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-2 host=localhost:9097 <checking_api_versions_recv> [IPv6 ('::1', 9097, 0, 0)]>: Broker version identified as 2.6
2026-01-21 00:21:10,765 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-2 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-21 00:21:10,798 - kafka.consumer.subscription_state - INFO - Updating subscribed topics to: ('example_topic',)
2026-01-21 00:21:10,864 - hdfs.client - INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
2026-01-21 00:21:10,922 - hdfs.client - INFO - Fetching content summary for '/'.
2026-01-21 00:21:11,341 - __main__ - INFO - ✅ Kết nối HDFS thành công tại: http://localhost:9870
2026-01-21 00:21:11,386 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-21 00:21:11,412 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-21 00:21:11,447 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-2 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-21 00:21:11,631 - kafka.cluster - INFO - Coordinator for group/hdfs_archiver_group is BrokerMetadata(nodeId='coordinator-1', host='localhost', port=9097, rack=None)
2026-01-21 00:21:11,672 - kafka.coordinator - INFO - Discovered coordinator coordinator-1 for group hdfs_archiver_group
2026-01-21 00:21:11,723 - kafka.coordinator.heartbeat - INFO - Starting new heartbeat thread
2026-01-21 00:21:11,827 - kafka.coordinator.consumer - INFO - Revoking previously assigned partitions set() for group hdfs_archiver_group
2026-01-21 00:21:11,883 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: NodeNotReadyError: coordinator-1
2026-01-21 00:21:11,947 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-21 00:21:12,002 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-21 00:21:12,211 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-21 00:21:12,822 - kafka.coordinator - INFO - Received member id kafka-python-2.3.0-9cdc8045-a8e0-4bf6-9a44-a482429f8e34 for group hdfs_archiver_group; will retry join-group
2026-01-21 00:21:12,878 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: [Error 79] MemberIdRequiredError
2026-01-21 00:21:12,973 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-21 00:21:16,965 - kafka.coordinator - INFO - Successfully joined group hdfs_archiver_group <Generation 21 (member_id: kafka-python-2.3.0-9cdc8045-a8e0-4bf6-9a44-a482429f8e34, protocol: range)>
2026-01-21 00:21:16,977 - kafka.coordinator - INFO - Elected group leader -- performing partition assignments using range
2026-01-21 00:21:17,105 - kafka.consumer.subscription_state - INFO - Updated partition assignment: [TopicPartition(topic='example_topic', partition=0)]
2026-01-21 00:21:17,125 - kafka.coordinator.consumer - INFO - Setting newly assigned partitions {TopicPartition(topic='example_topic', partition=0)} for group hdfs_archiver_group
2026-01-21 00:21:17,210 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connecting> [IPv6 ('::1', 9098, 0, 0)]>: connecting to localhost:9098 [('::1', 9098, 0, 0) IPv6]
2026-01-21 00:21:17,274 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Connection complete.
2026-01-21 00:21:17,758 - __main__ - INFO - Trigger write: 198 msgs (Timeout: False, Full: True)
2026-01-21 00:21:17,794 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:21:17,881 - hdfs.client - INFO - Creating directories to '/data/kafka_messages/2026/01/21'.
2026-01-21 00:21:18,179 - __main__ - INFO - Created HDFS directory: /data/kafka_messages/2026/01/21
2026-01-21 00:21:18,263 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_21_17_198.json'.
2026-01-21 00:21:18,380 - __main__ - ERROR - ❌ Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-21 00:22:13,371 - __main__ - INFO - 🛑 Consumer stopped by user.
2026-01-21 00:22:13,438 - __main__ - INFO - Đang ghi dữ liệu còn sót lại trước khi tắt...
2026-01-21 00:22:13,438 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:22:15,212 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_22_13_7.json'.
2026-01-21 00:22:15,238 - __main__ - ERROR - ❌ Lỗi ghi HDFS: Failed to find datanode, suggest to check cluster health. excludeDatanodes=null
2026-01-21 00:22:15,238 - kafka.coordinator.heartbeat - INFO - Stopping heartbeat thread
2026-01-21 00:22:15,239 - kafka.coordinator - INFO - Leaving consumer group hdfs_archiver_group (member kafka-python-2.3.0-9cdc8045-a8e0-4bf6-9a44-a482429f8e34).
2026-01-21 00:22:15,274 - kafka.coordinator - INFO - LeaveGroup request for group hdfs_archiver_group returned successfully
2026-01-21 00:22:15,275 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-21 00:22:15,275 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-21 00:22:15,276 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Closing connection. 
2026-01-21 00:22:15,276 - __main__ - INFO - Consumer closed.
2026-01-21 00:22:30,229 - __main__ - INFO - 🚀 Khởi động Consumer... Batch Size: 10
2026-01-21 00:22:30,443 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9098 <connecting> [IPv6 ('::1', 9098, 0, 0)]>: connecting to localhost:9098 [('::1', 9098, 0, 0) IPv6]
2026-01-21 00:22:30,608 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9098 <checking_api_versions_recv> [IPv6 ('::1', 9098, 0, 0)]>: Broker version identified as 2.6
2026-01-21 00:22:30,680 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Connection complete.
2026-01-21 00:22:30,796 - kafka.consumer.subscription_state - INFO - Updating subscribed topics to: ('example_topic',)
2026-01-21 00:22:30,858 - hdfs.client - INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
2026-01-21 00:22:30,901 - hdfs.client - INFO - Fetching content summary for '/'.
2026-01-21 00:22:31,178 - __main__ - INFO - ✅ Kết nối HDFS thành công tại: http://localhost:9870
2026-01-21 00:22:31,226 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-21 00:22:31,254 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-21 00:22:31,256 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Closing connection. 
2026-01-21 00:22:31,486 - kafka.cluster - INFO - Coordinator for group/hdfs_archiver_group is BrokerMetadata(nodeId='coordinator-1', host='localhost', port=9097, rack=None)
2026-01-21 00:22:31,501 - kafka.coordinator - INFO - Discovered coordinator coordinator-1 for group hdfs_archiver_group
2026-01-21 00:22:31,572 - kafka.coordinator.heartbeat - INFO - Starting new heartbeat thread
2026-01-21 00:22:31,649 - kafka.coordinator.consumer - INFO - Revoking previously assigned partitions set() for group hdfs_archiver_group
2026-01-21 00:22:31,672 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: NodeNotReadyError: coordinator-1
2026-01-21 00:22:31,731 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-21 00:22:31,765 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-21 00:22:31,989 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-21 00:22:32,037 - kafka.coordinator - INFO - Received member id kafka-python-2.3.0-0695aef9-be61-417c-91c6-2fe5792b8f98 for group hdfs_archiver_group; will retry join-group
2026-01-21 00:22:32,051 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: [Error 79] MemberIdRequiredError
2026-01-21 00:22:32,068 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-21 00:22:35,409 - kafka.coordinator - INFO - Successfully joined group hdfs_archiver_group <Generation 23 (member_id: kafka-python-2.3.0-0695aef9-be61-417c-91c6-2fe5792b8f98, protocol: range)>
2026-01-21 00:22:35,421 - kafka.coordinator - INFO - Elected group leader -- performing partition assignments using range
2026-01-21 00:22:35,624 - kafka.consumer.subscription_state - INFO - Updated partition assignment: [TopicPartition(topic='example_topic', partition=0)]
2026-01-21 00:22:35,637 - kafka.coordinator.consumer - INFO - Setting newly assigned partitions {TopicPartition(topic='example_topic', partition=0)} for group hdfs_archiver_group
2026-01-21 00:22:35,658 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connecting> [IPv6 ('::1', 9098, 0, 0)]>: connecting to localhost:9098 [('::1', 9098, 0, 0) IPv6]
2026-01-21 00:22:35,674 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Connection complete.
2026-01-21 00:22:35,777 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-21 00:22:35,785 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:22:35,820 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_22_35_10.json'.
2026-01-21 00:22:53,531 - __main__ - INFO - 💾 Đã lưu 10 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_22_35_10.json
2026-01-21 00:23:43,328 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-21 00:23:43,389 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:23:43,696 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_23_43_10.json'.
2026-01-21 00:23:50,784 - __main__ - INFO - 💾 Đã lưu 10 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_23_43_10.json
2026-01-21 00:24:51,083 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-21 00:24:51,096 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:24:51,199 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_24_51_8.json'.
2026-01-21 00:24:54,423 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_24_51_8.json
2026-01-21 00:25:48,722 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-21 00:25:48,743 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:25:48,855 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_25_48_10.json'.
2026-01-21 00:25:54,450 - __main__ - INFO - 💾 Đã lưu 10 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_25_48_10.json
2026-01-21 00:26:55,580 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 00:26:55,591 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:26:55,817 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_26_55_9.json'.
2026-01-21 00:26:58,674 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_26_55_9.json
2026-01-21 00:28:03,466 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 00:28:03,504 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:28:03,664 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_28_03_9.json'.
2026-01-21 00:28:04,764 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_28_03_9.json
2026-01-21 00:29:07,741 - __main__ - INFO - Trigger write: 7 msgs (Timeout: True, Full: False)
2026-01-21 00:29:07,758 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:29:07,913 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_29_07_7.json'.
2026-01-21 00:29:12,099 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 219, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_29_07_7.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_29_07_7.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-21 00:29:12,468 - __main__ - ERROR - ❌ Lỗi ghi HDFS: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_29_07_7.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-21 00:30:12,867 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 00:30:12,907 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:30:13,157 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_30_12_9.json'.
2026-01-21 00:30:17,507 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 219, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_30_12_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_30_12_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-21 00:30:17,576 - __main__ - ERROR - ❌ Lỗi ghi HDFS: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_30_12_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-21 00:31:18,630 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 00:31:18,636 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:31:18,780 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_31_18_9.json'.
2026-01-21 00:31:22,935 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 219, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_31_18_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_31_18_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-21 00:31:22,941 - __main__ - ERROR - ❌ Lỗi ghi HDFS: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_31_18_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-21 00:32:25,362 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-21 00:32:25,390 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:32:25,581 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_32_25_8.json'.
2026-01-21 00:32:29,920 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 219, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_32_25_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_32_25_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-21 00:32:29,931 - __main__ - ERROR - ❌ Lỗi ghi HDFS: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_32_25_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-21 00:33:30,766 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 00:33:30,802 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:33:30,851 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_33_30_9.json'.
2026-01-21 00:33:35,023 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    raise err
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 219, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_33_30_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_33_30_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-21 00:33:35,036 - __main__ - ERROR - ❌ Lỗi ghi HDFS: HTTPConnectionPool(host='localhost', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_33_30_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NewConnectionError("HTTPConnection(host='localhost', port=9864): Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it"))
2026-01-21 00:34:07,636 - __main__ - INFO - 🛑 Consumer stopped by user.
2026-01-21 00:34:07,648 - __main__ - INFO - Đang ghi dữ liệu còn sót lại trước khi tắt...
2026-01-21 00:34:07,662 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:34:07,754 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_34_07_4.json'.
2026-01-21 00:34:07,894 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 571, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
http.client.RemoteDisconnected: Remote end closed connection without response

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 490, in increment
    raise reraise(type(error), error, _stacktrace)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\util.py", line 38, in reraise
    raise value.with_traceback(tb)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 571, in getresponse
    httplib_response = super().getresponse()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 287, in _read_status
    raise RemoteDisconnected("Remote end closed connection without"
urllib3.exceptions.ProtocolError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2026-01-21 00:34:07,942 - __main__ - ERROR - ❌ Lỗi ghi HDFS: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
2026-01-21 00:34:07,957 - kafka.coordinator.heartbeat - INFO - Stopping heartbeat thread
2026-01-21 00:34:08,000 - kafka.coordinator - INFO - Leaving consumer group hdfs_archiver_group (member kafka-python-2.3.0-0695aef9-be61-417c-91c6-2fe5792b8f98).
2026-01-21 00:34:08,045 - kafka.coordinator - INFO - LeaveGroup request for group hdfs_archiver_group returned successfully
2026-01-21 00:34:08,075 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-21 00:34:08,093 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-21 00:34:08,114 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Closing connection. 
2026-01-21 00:34:08,129 - __main__ - INFO - Consumer closed.
2026-01-21 00:36:01,135 - __main__ - INFO - 🚀 Khởi động Consumer... Batch Size: 10
2026-01-21 00:36:01,182 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-21 00:36:01,366 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9097 <checking_api_versions_recv> [IPv6 ('::1', 9097, 0, 0)]>: Broker version identified as 2.6
2026-01-21 00:36:01,373 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-21 00:36:01,386 - kafka.consumer.subscription_state - INFO - Updating subscribed topics to: ('example_topic',)
2026-01-21 00:36:01,389 - hdfs.client - INFO - Instantiated <InsecureClient(url='http://localhost:9870')>.
2026-01-21 00:36:01,402 - hdfs.client - INFO - Fetching content summary for '/'.
2026-01-21 00:36:01,535 - __main__ - INFO - ✅ Kết nối HDFS thành công tại: http://localhost:9870
2026-01-21 00:36:01,555 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connecting> [IPv6 ('::1', 9098, 0, 0)]>: connecting to localhost:9098 [('::1', 9098, 0, 0) IPv6]
2026-01-21 00:36:01,564 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Connection complete.
2026-01-21 00:36:01,567 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=bootstrap-0 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-21 00:36:01,699 - kafka.cluster - INFO - Coordinator for group/hdfs_archiver_group is BrokerMetadata(nodeId='coordinator-1', host='localhost', port=9097, rack=None)
2026-01-21 00:36:01,724 - kafka.coordinator - INFO - Discovered coordinator coordinator-1 for group hdfs_archiver_group
2026-01-21 00:36:01,732 - kafka.coordinator.heartbeat - INFO - Starting new heartbeat thread
2026-01-21 00:36:01,801 - kafka.coordinator.consumer - INFO - Revoking previously assigned partitions set() for group hdfs_archiver_group
2026-01-21 00:36:01,815 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: NodeNotReadyError: coordinator-1
2026-01-21 00:36:01,833 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-21 00:36:01,835 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-21 00:36:01,978 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-21 00:36:02,022 - kafka.coordinator - INFO - Received member id kafka-python-2.3.0-10773a49-0973-4b63-aad7-2b1fceed00bb for group hdfs_archiver_group; will retry join-group
2026-01-21 00:36:02,028 - kafka.coordinator - INFO - Failed to join group hdfs_archiver_group: [Error 79] MemberIdRequiredError
2026-01-21 00:36:02,028 - kafka.coordinator - INFO - (Re-)joining group hdfs_archiver_group
2026-01-21 00:36:05,373 - kafka.coordinator - INFO - Successfully joined group hdfs_archiver_group <Generation 25 (member_id: kafka-python-2.3.0-10773a49-0973-4b63-aad7-2b1fceed00bb, protocol: range)>
2026-01-21 00:36:05,389 - kafka.coordinator - INFO - Elected group leader -- performing partition assignments using range
2026-01-21 00:36:05,443 - kafka.consumer.subscription_state - INFO - Updated partition assignment: [TopicPartition(topic='example_topic', partition=0)]
2026-01-21 00:36:05,459 - kafka.coordinator.consumer - INFO - Setting newly assigned partitions {TopicPartition(topic='example_topic', partition=0)} for group hdfs_archiver_group
2026-01-21 00:36:05,526 - __main__ - INFO - Trigger write: 21 msgs (Timeout: False, Full: True)
2026-01-21 00:36:05,532 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:36:05,563 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_36_05_21.json'.
2026-01-21 00:36:34,978 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 515, in consumer
    raise _to_error(res)
hdfs.util.HdfsError: File /data/kafka_messages/2026/01/21/batdongsan_00_36_05_21.json could only be written to 0 of the 1 minReplication nodes. There are 1 datanode(s) running and 1 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2219)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

2026-01-21 00:36:34,990 - __main__ - ERROR - ❌ Lỗi ghi HDFS: File /data/kafka_messages/2026/01/21/batdongsan_00_36_05_21.json could only be written to 0 of the 1 minReplication nodes. There are 1 datanode(s) running and 1 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2219)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

2026-01-21 00:37:13,473 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-21 00:37:13,486 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:37:13,769 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_37_13_10.json'.
2026-01-21 00:37:37,723 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 515, in consumer
    raise _to_error(res)
hdfs.util.HdfsError: File /data/kafka_messages/2026/01/21/batdongsan_00_37_13_10.json could only be written to 0 of the 1 minReplication nodes. There are 1 datanode(s) running and 1 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2219)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

2026-01-21 00:37:37,740 - __main__ - ERROR - ❌ Lỗi ghi HDFS: File /data/kafka_messages/2026/01/21/batdongsan_00_37_13_10.json could only be written to 0 of the 1 minReplication nodes. There are 1 datanode(s) running and 1 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2219)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2789)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:892)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:574)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:528)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:999)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:927)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2915)

2026-01-21 00:38:23,887 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-21 00:38:23,900 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:38:24,068 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_38_23_10.json'.
2026-01-21 00:38:27,175 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_38_23_10.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_38_23_10.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-21 00:38:27,204 - __main__ - ERROR - ❌ Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_38_23_10.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-21 00:39:33,276 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 00:39:33,297 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:39:33,451 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_39_33_9.json'.
2026-01-21 00:39:36,286 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_39_33_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_39_33_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-21 00:39:36,324 - __main__ - ERROR - ❌ Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_39_33_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-21 00:40:39,893 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 00:40:39,904 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:40:39,963 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_40_39_9.json'.
2026-01-21 00:40:42,929 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_40_39_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_40_39_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-21 00:40:42,955 - __main__ - ERROR - ❌ Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_40_39_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-21 00:41:05,430 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-21 00:41:05,441 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-21 00:41:45,274 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-21 00:41:45,281 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:41:45,375 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_41_45_8.json'.
2026-01-21 00:41:48,203 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_41_45_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_41_45_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-21 00:41:48,249 - __main__ - ERROR - ❌ Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_41_45_8.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-21 00:42:49,029 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 00:42:49,057 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:42:49,301 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_42_49_9.json'.
2026-01-21 00:42:52,172 - hdfs.util - ERROR - Exception in child.
Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 204, in _new_conn
    sock = connection.create_connection(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\socket.py", line 955, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 500, in request
    self.endheaders()
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\Admin\AppData\Local\Programs\Python\Python310\lib\http\client.py", line 975, in send
    self.connect()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 331, in connect
    self.sock = self._new_conn()
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connection.py", line 211, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\urllib3\util\retry.py", line 535, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_42_49_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\util.py", line 76, in consumer
    self._consumer(data)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 509, in consumer
    res = self._request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\hdfs\client.py", line 209, in _request
    return self._session.request(
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\BTL_Big_Data\Big_Data_20251\venv\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_42_49_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-21 00:42:52,215 - __main__ - ERROR - ❌ Lỗi ghi HDFS: HTTPConnectionPool(host='datanode-1', port=9864): Max retries exceeded with url: /webhdfs/v1/data/kafka_messages/2026/01/21/batdongsan_00_42_49_9.json?op=CREATE&user.name=root&namenoderpcaddress=namenode:9000&createflag=&createparent=true&overwrite=true&user.name=root (Caused by NameResolutionError("HTTPConnection(host='datanode-1', port=9864): Failed to resolve 'datanode-1' ([Errno 11001] getaddrinfo failed)"))
2026-01-21 00:43:52,815 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-21 00:43:52,833 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:43:52,923 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_43_52_8.json'.
2026-01-21 00:43:59,374 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_43_52_8.json
2026-01-21 00:45:01,489 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 00:45:01,565 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:45:01,790 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_45_01_9.json'.
2026-01-21 00:45:09,451 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_45_01_9.json
2026-01-21 00:46:10,166 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 00:46:10,202 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:46:10,437 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_46_10_9.json'.
2026-01-21 00:46:14,617 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_46_10_9.json
2026-01-21 00:47:14,797 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 00:47:14,810 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:47:14,911 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_47_14_9.json'.
2026-01-21 00:47:19,744 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_47_14_9.json
2026-01-21 00:48:16,015 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-21 00:48:16,066 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:48:16,173 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_48_16_10.json'.
2026-01-21 00:48:18,834 - __main__ - INFO - 💾 Đã lưu 10 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_48_16_10.json
2026-01-21 00:49:26,244 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-21 00:49:26,262 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:49:26,398 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_49_26_8.json'.
2026-01-21 00:49:28,850 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_49_26_8.json
2026-01-21 00:50:30,183 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 00:50:30,201 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:50:30,270 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_50_30_9.json'.
2026-01-21 00:50:35,836 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_50_30_9.json
2026-01-21 00:51:36,068 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-21 00:51:36,077 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:51:36,188 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_51_36_8.json'.
2026-01-21 00:51:40,152 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_51_36_8.json
2026-01-21 00:52:41,005 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 00:52:41,029 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:52:41,240 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_52_41_9.json'.
2026-01-21 00:52:48,282 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_52_41_9.json
2026-01-21 00:53:48,866 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-21 00:53:49,013 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:53:49,210 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_53_49_8.json'.
2026-01-21 00:53:58,745 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_53_49_8.json
2026-01-21 00:54:59,849 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 00:54:59,870 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:54:59,970 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_54_59_9.json'.
2026-01-21 00:55:04,672 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_54_59_9.json
2026-01-21 00:56:05,511 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 00:56:05,526 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:56:05,658 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_56_05_9.json'.
2026-01-21 00:56:11,764 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_56_05_9.json
2026-01-21 00:57:11,997 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-21 00:57:12,012 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:57:12,372 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_57_12_8.json'.
2026-01-21 00:57:16,997 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_57_12_8.json
2026-01-21 00:58:17,106 - __main__ - INFO - Trigger write: 7 msgs (Timeout: True, Full: False)
2026-01-21 00:58:17,130 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:58:17,614 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_58_17_7.json'.
2026-01-21 00:58:27,630 - __main__ - INFO - 💾 Đã lưu 7 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_58_17_7.json
2026-01-21 00:59:20,950 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-21 00:59:20,960 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 00:59:21,181 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_00_59_20_10.json'.
2026-01-21 00:59:28,595 - __main__ - INFO - 💾 Đã lưu 10 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_00_59_20_10.json
2026-01-21 01:00:29,828 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-21 01:00:29,840 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:00:29,877 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_00_29_8.json'.
2026-01-21 01:00:32,246 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_00_29_8.json
2026-01-21 01:01:32,669 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 01:01:32,675 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:01:32,785 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_01_32_9.json'.
2026-01-21 01:01:35,761 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_01_32_9.json
2026-01-21 01:02:38,671 - __main__ - INFO - Trigger write: 7 msgs (Timeout: True, Full: False)
2026-01-21 01:02:38,686 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:02:38,813 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_02_38_7.json'.
2026-01-21 01:02:43,958 - __main__ - INFO - 💾 Đã lưu 7 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_02_38_7.json
2026-01-21 01:03:36,924 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-21 01:03:36,935 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:03:36,977 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_03_36_10.json'.
2026-01-21 01:03:44,361 - __main__ - INFO - 💾 Đã lưu 10 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_03_36_10.json
2026-01-21 01:04:44,567 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 01:04:44,581 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:04:44,637 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_04_44_9.json'.
2026-01-21 01:04:47,615 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_04_44_9.json
2026-01-21 01:05:42,866 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-21 01:05:42,886 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:05:43,307 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_05_42_10.json'.
2026-01-21 01:05:51,048 - __main__ - INFO - 💾 Đã lưu 10 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_05_42_10.json
2026-01-21 01:06:52,437 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-21 01:06:52,452 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:06:52,511 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_06_52_8.json'.
2026-01-21 01:06:55,380 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_06_52_8.json
2026-01-21 01:07:52,661 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-21 01:07:52,685 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:07:52,776 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_07_52_10.json'.
2026-01-21 01:07:56,372 - __main__ - INFO - 💾 Đã lưu 10 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_07_52_10.json
2026-01-21 01:09:01,566 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 01:09:01,592 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:09:01,683 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_09_01_9.json'.
2026-01-21 01:09:07,976 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_09_01_9.json
2026-01-21 01:10:08,541 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 01:10:08,550 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:10:08,674 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_10_08_9.json'.
2026-01-21 01:10:13,321 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_10_08_9.json
2026-01-21 01:11:16,298 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-21 01:11:16,303 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:11:16,360 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_11_16_10.json'.
2026-01-21 01:11:20,801 - __main__ - INFO - 💾 Đã lưu 10 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_11_16_10.json
2026-01-21 01:12:23,882 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 01:12:23,906 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:12:24,321 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_12_23_9.json'.
2026-01-21 01:12:29,364 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_12_23_9.json
2026-01-21 01:13:32,786 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-21 01:13:32,805 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:13:33,008 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_13_32_8.json'.
2026-01-21 01:13:36,161 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_13_32_8.json
2026-01-21 01:14:36,612 - __main__ - INFO - Trigger write: 7 msgs (Timeout: True, Full: False)
2026-01-21 01:14:36,616 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:14:36,782 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_14_36_7.json'.
2026-01-21 01:14:41,469 - __main__ - INFO - 💾 Đã lưu 7 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_14_36_7.json
2026-01-21 01:15:42,183 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 01:15:42,195 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:15:42,275 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_15_42_9.json'.
2026-01-21 01:15:45,504 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_15_42_9.json
2026-01-21 01:16:46,845 - __main__ - INFO - Trigger write: 7 msgs (Timeout: True, Full: False)
2026-01-21 01:16:46,852 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:16:46,973 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_16_46_7.json'.
2026-01-21 01:16:53,393 - __main__ - INFO - 💾 Đã lưu 7 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_16_46_7.json
2026-01-21 01:17:53,591 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 01:17:53,610 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:17:53,798 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_17_53_9.json'.
2026-01-21 01:17:58,694 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_17_53_9.json
2026-01-21 01:18:58,985 - __main__ - INFO - Trigger write: 7 msgs (Timeout: True, Full: False)
2026-01-21 01:18:59,001 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:18:59,149 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_18_59_7.json'.
2026-01-21 01:19:05,258 - __main__ - INFO - 💾 Đã lưu 7 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_18_59_7.json
2026-01-21 01:20:06,266 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 01:20:06,301 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:20:06,653 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_20_06_9.json'.
2026-01-21 01:20:10,561 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_20_06_9.json
2026-01-21 01:21:12,562 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-21 01:21:12,586 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:21:12,760 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_21_12_8.json'.
2026-01-21 01:21:19,501 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_21_12_8.json
2026-01-21 01:22:19,856 - __main__ - INFO - Trigger write: 10 msgs (Timeout: True, Full: True)
2026-01-21 01:22:19,879 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:22:20,003 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_22_19_10.json'.
2026-01-21 01:22:24,646 - __main__ - INFO - 💾 Đã lưu 10 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_22_19_10.json
2026-01-21 01:23:29,151 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-21 01:23:29,180 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:23:29,299 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_23_29_8.json'.
2026-01-21 01:23:36,420 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_23_29_8.json
2026-01-21 01:24:31,800 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-21 01:24:31,812 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:24:31,939 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_24_31_10.json'.
2026-01-21 01:24:35,810 - __main__ - INFO - 💾 Đã lưu 10 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_24_31_10.json
2026-01-21 01:25:39,203 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-21 01:25:39,242 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:25:39,482 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_25_39_8.json'.
2026-01-21 01:25:44,545 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_25_39_8.json
2026-01-21 01:26:44,592 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-21 01:26:44,611 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:26:44,655 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_26_44_8.json'.
2026-01-21 01:26:46,398 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_26_44_8.json
2026-01-21 01:27:51,941 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 01:27:51,954 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:27:52,051 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_27_51_9.json'.
2026-01-21 01:27:57,344 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_27_51_9.json
2026-01-21 01:28:58,232 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-21 01:28:58,242 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:28:58,545 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_28_58_8.json'.
2026-01-21 01:29:03,411 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_28_58_8.json
2026-01-21 01:30:04,442 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 01:30:04,451 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:30:04,550 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_30_04_9.json'.
2026-01-21 01:30:09,248 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_30_04_9.json
2026-01-21 01:31:08,912 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-21 01:31:08,927 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:31:09,061 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_31_08_10.json'.
2026-01-21 01:31:13,472 - __main__ - INFO - 💾 Đã lưu 10 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_31_08_10.json
2026-01-21 01:32:18,230 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 01:32:18,240 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:32:18,346 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_32_18_9.json'.
2026-01-21 01:32:22,384 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_32_18_9.json
2026-01-21 01:33:23,496 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 01:33:23,503 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:33:23,670 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_33_23_9.json'.
2026-01-21 01:33:27,152 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_33_23_9.json
2026-01-21 01:34:29,758 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-21 01:34:29,780 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:34:29,954 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_34_29_8.json'.
2026-01-21 01:34:36,982 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_34_29_8.json
2026-01-21 01:35:10,381 - kafka.client - INFO - Closing idle connection 1, last active 540000 ms ago
2026-01-21 01:35:10,393 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-21 01:35:35,261 - __main__ - INFO - Trigger write: 10 msgs (Timeout: False, Full: True)
2026-01-21 01:35:35,359 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:35:35,700 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_35_35_10.json'.
2026-01-21 01:35:47,675 - __main__ - INFO - 💾 Đã lưu 10 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_35_35_10.json
2026-01-21 01:36:13,512 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connecting> [IPv6 ('::1', 9097, 0, 0)]>: connecting to localhost:9097 [('::1', 9097, 0, 0) IPv6]
2026-01-21 01:36:13,521 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Connection complete.
2026-01-21 01:36:48,701 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 01:36:48,729 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:36:48,817 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_36_48_9.json'.
2026-01-21 01:36:57,909 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_36_48_9.json
2026-01-21 01:37:58,377 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 01:37:58,437 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:37:58,611 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_37_58_9.json'.
2026-01-21 01:38:07,456 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_37_58_9.json
2026-01-21 01:39:07,602 - __main__ - INFO - Trigger write: 9 msgs (Timeout: True, Full: False)
2026-01-21 01:39:07,618 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:39:07,774 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_39_07_9.json'.
2026-01-21 01:39:11,141 - __main__ - INFO - 💾 Đã lưu 9 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_39_07_9.json
2026-01-21 01:40:12,326 - __main__ - INFO - Trigger write: 8 msgs (Timeout: True, Full: False)
2026-01-21 01:40:12,421 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:40:13,127 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_40_12_8.json'.
2026-01-21 01:40:38,942 - __main__ - INFO - 💾 Đã lưu 8 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_40_12_8.json
2026-01-21 01:40:51,372 - __main__ - INFO - 🛑 Consumer stopped by user.
2026-01-21 01:40:51,448 - __main__ - INFO - Đang ghi dữ liệu còn sót lại trước khi tắt...
2026-01-21 01:40:51,577 - hdfs.client - INFO - Fetching status for '/data/kafka_messages/2026/01/21'.
2026-01-21 01:40:51,732 - hdfs.client - INFO - Writing to '/data/kafka_messages/2026/01/21/batdongsan_01_40_51_5.json'.
2026-01-21 01:40:56,959 - __main__ - INFO - 💾 Đã lưu 5 tin vào HDFS: /data/kafka_messages/2026/01/21/batdongsan_01_40_51_5.json
2026-01-21 01:40:56,970 - kafka.coordinator.heartbeat - INFO - Stopping heartbeat thread
2026-01-21 01:40:56,972 - kafka.coordinator - INFO - Leaving consumer group hdfs_archiver_group (member kafka-python-2.3.0-10773a49-0973-4b63-aad7-2b1fceed00bb).
2026-01-21 01:40:57,355 - kafka.coordinator - INFO - LeaveGroup request for group hdfs_archiver_group returned successfully
2026-01-21 01:40:57,364 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=2 host=localhost:9098 <connected> [IPv6 ('::1', 9098, 0, 0)]>: Closing connection. 
2026-01-21 01:40:57,380 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=coordinator-1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-21 01:40:57,391 - kafka.conn - INFO - <BrokerConnection client_id=kafka-python-2.3.0, node_id=1 host=localhost:9097 <connected> [IPv6 ('::1', 9097, 0, 0)]>: Closing connection. 
2026-01-21 01:40:57,393 - __main__ - INFO - Consumer closed.
