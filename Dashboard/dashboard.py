import streamlit as st
import pandas as pd
import plotly.express as px
import os
import sys

# ==========================================
# 0. C·∫§U H√åNH M√îI TR∆Ø·ªúNG "XE TƒÇNG"
# ==========================================
os.environ['HADOOP_HOME'] = "D:\\hadoop"
sys.path.append("D:\\hadoop\\bin")
os.environ['JAVA_HOME'] = "C:\\Program Files\\Eclipse Adoptium\\jdk-11.0.29.7-hotspot"
os.environ['PATH'] = os.environ['JAVA_HOME'] + "\\bin;" + os.environ['PATH']

# C·∫•u h√¨nh m·∫°ng ƒë·ªÉ Spark kh√¥ng b·ªã l·∫°c l·ªëi tr√™n Windows
os.environ['PYSPARK_PYTHON'] = sys.executable
os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable
os.environ['SPARK_LOCAL_IP'] = '127.0.0.1'

from pyspark.sql import SparkSession
from pyspark.ml import PipelineModel
from pyspark.sql.types import DoubleType
from pyspark.sql.functions import lit, col, lower, when

# ==========================================
# 1. SETUP SPARK SESSION
# ==========================================
@st.cache_resource
def get_spark_session():
    return SparkSession.builder \
    .appName("HanoiHousePrice_Dashboard") \
    .master("local[1]") \
    \
    .config("spark.driver.host", "127.0.0.1") \
    .config("spark.driver.bindAddress", "127.0.0.1") \
    \
    .config("spark.network.timeout", "600s") \
    .config("spark.executor.heartbeatInterval", "120s") \
    \
    .config("spark.driver.memory", "4g") \
    .config("spark.executor.memory", "4g") \
    .config("spark.sql.shuffle.partitions", "4") \
    \
    .config("spark.hadoop.fs.defaultFS", "hdfs://localhost:9000") \
    .config("spark.hadoop.dfs.client.use.datanode.hostname", "true") \
    \
    .config("spark.jars.packages", "com.datastax.spark:spark-cassandra-connector_2.12:3.3.0") \
    .config("spark.cassandra.connection.host", "localhost") \
    .config("spark.cassandra.connection.port", "9042") \
    .getOrCreate()

@st.cache_resource
def load_trained_model(_spark):
    try:
        model_path = "file:///D:/BTL_Big_Data/Big_Data_20251/saved_models"
        return PipelineModel.load(model_path)
    except Exception as e:
        st.error(f"‚ùå Kh√¥ng th·ªÉ load Model: {e}")
        return None

spark = get_spark_session()
model = load_trained_model(spark)

# ==========================================
# 2. HELPER FUNCTIONS
# ==========================================
def get_market_stats():
    """L·∫•y th·ªëng k√™ th·ªã tr∆∞·ªùng t·ª´ b·∫£ng data2"""
    try:
        df = spark.read \
            .format("org.apache.spark.sql.cassandra") \
            .options(table="data2", keyspace="finaldata1") \
            .load()
        df.createOrReplaceTempView("market_data")
        
        return spark.sql("""
            SELECT city, COUNT(*) as count, AVG(price) as avg_price 
            FROM market_data WHERE city IS NOT NULL GROUP BY city
        """).toPandas()
    except:
        return pd.DataFrame()

def predict_price(input_dict):
    """D·ª± ƒëo√°n gi√° cho cƒÉn nh√† nh·∫≠p tay"""
    if not model: return 0.0
    
    # T·∫°o DataFrame t·ª´ input
    df = spark.createDataFrame([input_dict])
    
    # Feature Engineering (T√°i t·∫°o logic l√∫c train)
    if "description" not in df.columns: df = df.withColumn("description", lit(""))
    
    df = df.withColumn("desc_lower", lower(col("description"))) \
           .withColumn("has_red_book", when(col("desc_lower").rlike("s·ªï ƒë·ªè|s·ªï h·ªìng|ch√≠nh ch·ªß"), 1.0).otherwise(0.0)) \
           .withColumn("is_street_front", when(col("desc_lower").rlike("m·∫∑t ti·ªÅn|m·∫∑t ph·ªë|kinh doanh"), 1.0).otherwise(0.0)) \
           .withColumn("is_wide_alley", when(col("desc_lower").rlike("xe h∆°i|√¥ t√¥|oto"), 1.0).otherwise(0.0))
    
    for c in ['city', 'homeType', 'newConstructionType']:
        if c not in df.columns: df = df.withColumn(c, lit("UNKNOWN"))
        
    for c in ['isFeatured', 'isShowcaseListing']:
        if c not in df.columns: df = df.withColumn(c, lit(0.0))
        
    cols_to_cast = ['lotAreaValue', 'bathrooms', 'bedrooms', 'livingArea', 
                    'has_red_book', 'is_street_front', 'is_wide_alley', 
                    'isFeatured', 'isShowcaseListing']
    for c in cols_to_cast:
        df = df.withColumn(c, col(c).cast(DoubleType()))
        
    return model.transform(df).select("prediction").collect()[0][0]

# ==========================================
# 3. GIAO DI·ªÜN CH√çNH
# ==========================================
st.set_page_config(page_title="Real Estate AI Hub", layout="wide", page_icon="üè†")

st.title("üè† Real Estate AI Analytics Center")
st.markdown("#### *H·ªá th·ªëng Ph√¢n t√≠ch & ƒê·ªãnh gi√° B·∫•t ƒë·ªông s·∫£n Th√¥ng minh*")
st.markdown("---")

# --- TAB NAVIGATION ---
tab1, tab2, tab3 = st.tabs(["üìä Th·ªã tr∆∞·ªùng", "üîÆ ƒê·ªãnh gi√° AI", "üîç T√¨m nh√† (Smart Search)"])

# ----------------------------------------------------
# TAB 1: TH·ªä TR∆Ø·ªúNG
# ----------------------------------------------------
with tab1:
    st.header("T·ªïng quan Th·ªã tr∆∞·ªùng H√† N·ªôi")
    if st.button("üîÑ Refresh Data", key="btn_refresh"):
        st.cache_data.clear()
        
    stats = get_market_stats()
    if not stats.empty:
        c1, c2 = st.columns(2)
        c1.metric("T·ªïng tin ƒëƒÉng", f"{stats['count'].sum():,}")
        c2.metric("Gi√° TB to√†n th·ªã tr∆∞·ªùng", f"{stats['avg_price'].mean()/1e9:,.2f} T·ª∑")
        
        fig = px.bar(stats, x='city', y='avg_price', color='count', 
                     title="M·∫∑t b·∫±ng gi√° theo Qu·∫≠n", labels={'avg_price': 'Gi√° TB (VNƒê)'})
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.warning("ƒêang ch·ªù d·ªØ li·ªáu t·ª´ h·ªá th·ªëng Big Data...")

# ----------------------------------------------------
# TAB 2: ƒê·ªäNH GI√Å (PREDICTION)
# ----------------------------------------------------
with tab2:
    st.header("C√¥ng c·ª• ƒê·ªãnh gi√° Nh√† AI")
    st.caption("Nh·∫≠p th√¥ng tin cƒÉn nh√† ƒë·ªÉ AI ∆∞·ªõc t√≠nh gi√° tr·ªã th·ª±c")
    
    col1, col2 = st.columns(2)
    with col1:
        p_city = st.selectbox("Qu·∫≠n/Huy·ªán", ["H√† ƒê√¥ng", "C·∫ßu Gi·∫•y", "ƒê·ªëng ƒêa", "Thanh Xu√¢n", "Ho√†ng Mai", "Hai B√† Tr∆∞ng", "T√¢y H·ªì"])
        p_area = st.number_input("Di·ªán t√≠ch (m2)", 10.0, 500.0, 50.0)
        p_desc = st.text_area("M√¥ t·∫£ ƒë·∫∑c ƒëi·ªÉm", "Nh√† ch√≠nh ch·ªß, c√≥ s·ªï ƒë·ªè, ng√µ √¥ t√¥ ƒë·ªó c·ª≠a")
    with col2:
        p_bed = st.number_input("Ph√≤ng ng·ªß", 1, 10, 2)
        p_bath = st.number_input("Ph√≤ng t·∫Øm", 1, 10, 2)
        st.markdown("<br>", unsafe_allow_html=True) # Spacer
        if st.button("üöÄ ƒê·ªãnh gi√° ngay", type="primary"):
            with st.spinner("AI ƒëang ph√¢n t√≠ch h√†ng tri·ªáu d·ªØ li·ªáu..."):
                val = predict_price({
                    "city": p_city, "lotAreaValue": p_area, "livingArea": p_area,
                    "bedrooms": p_bed, "bathrooms": p_bath, "description": p_desc
                })
                st.success(f"üíé AI ƒë·ªãnh gi√° cƒÉn nh√† n√†y kho·∫£ng: **{val/1e9:,.2f} T·ª∑ VNƒê**")

# ----------------------------------------------------
# TAB 3: T√åM NH√Ä (SMART SEARCH) - ƒê√É C·∫¨P NH·∫¨T
# ----------------------------------------------------
with tab3:
    st.header("T√¨m ki·∫øm Nh√† theo Nhu c·∫ßu")
    st.caption("T√¨m c√°c cƒÉn nh√† th·ª±c t·∫ø ƒëang b√°n kh·ªõp v·ªõi t√∫i ti·ªÅn c·ªßa b·∫°n")
    
    # 1. Input Filter
    c1, c2, c3 = st.columns(3)
    with c1:
        budget = st.number_input("Ng√¢n s√°ch c·ªßa b·∫°n (T·ª∑ VNƒê)", 1.0, 50.0, 3.0, step=0.5)
    with c2:
        target_cities = st.multiselect("Khu v·ª±c mong mu·ªën", 
                                       ["H√† ƒê√¥ng", "C·∫ßu Gi·∫•y", "ƒê·ªëng ƒêa", "Thanh Xu√¢n", "Ho√†ng Mai", "T√¢y H·ªì"],
                                       default=["H√† ƒê√¥ng", "Thanh Xu√¢n"])
    with c3:
        min_bed = st.slider("S·ªë ph√≤ng ng·ªß t·ªëi thi·ªÉu", 1, 5, 2)

    # 2. Logic T√¨m ki·∫øm
    if st.button("üîé T√¨m nh√† ph√π h·ª£p"):
        try:
            # Load d·ªØ li·ªáu g·ªëc t·ª´ Cassandra (Table data2)
            df_search = spark.read \
                .format("org.apache.spark.sql.cassandra") \
                .options(table="data2", keyspace="finaldata1") \
                .load()
            
            df_search.createOrReplaceTempView("all_houses")
            
            # Logic: T√¨m nh√† gi√° ch√™nh l·ªách +/- 20% so v·ªõi ng√¢n s√°ch
            min_p = (budget * 1e9) * 0.8
            max_p = (budget * 1e9) * 1.2
            
            # X√¢y d·ª±ng c√¢u SQL linh ƒë·ªông
            city_condition = ""
            if target_cities:
                cities_str = "', '".join(target_cities)
                city_condition = f"AND city IN ('{cities_str}')"
            
            # Query (L∆∞u √Ω: T√™n c·ªôt trong Cassandra th∆∞·ªùng l√† ch·ªØ th∆∞·ªùng)
            query = f"""
                SELECT zpid, city, price, livingarea, bedrooms, bathrooms 
                FROM all_houses 
                WHERE price >= {min_p} 
                  AND price <= {max_p} 
                  AND bedrooms >= {min_bed}
                  {city_condition}
                LIMIT 20
            """
            
            results = spark.sql(query).toPandas()
            
            # 3. Hi·ªÉn th·ªã k·∫øt qu·∫£
            if not results.empty:
                st.success(f"üéâ T√¨m th·∫•y {len(results)} cƒÉn nh√† ph√π h·ª£p v·ªõi ng√¢n s√°ch ~{budget} T·ª∑!")
                
                # Format l·∫°i hi·ªÉn th·ªã cho ƒë·∫πp
                results['Gi√° (T·ª∑)'] = results['price'].apply(lambda x: f"{x/1e9:.2f}")
                results['Di·ªán t√≠ch'] = results['livingarea'].apply(lambda x: f"{x:.0f} m¬≤")
                
                # Show b·∫£ng (·∫®n c√°c c·ªôt th√¥ ƒëi)
                st.dataframe(
                    results[['city', 'Gi√° (T·ª∑)', 'Di·ªán t√≠ch', 'bedrooms', 'bathrooms', 'zpid']],
                    use_container_width=True,
                    hide_index=True
                )
            else:
                st.warning(f"Kh√¥ng t√¨m th·∫•y cƒÉn n√†o quanh m·ª©c gi√° {budget} T·ª∑ ·ªü khu v·ª±c n√†y. H√£y th·ª≠ n·ªõi r·ªông ng√¢n s√°ch!")
                
        except Exception as e:
            st.error(f"L·ªói truy v·∫•n d·ªØ li·ªáu: {e}")
            st.info("M·∫πo: Ki·ªÉm tra l·∫°i xem b·∫£ng 'data2' trong Cassandra ƒë√£ c√≥ d·ªØ li·ªáu ch∆∞a.")